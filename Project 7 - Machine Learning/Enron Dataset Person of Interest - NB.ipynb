{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1a)  Goal of this project:\n",
    "The end goal of this project is to use the available Enron dataset and build a Machine learning model that could classify whether a person is a Person of Interest (POI) or not. Here the POI refers to the individual who were tried for fraud or criminal activity and not just those who were convicted. The dataset used comprises of Financial data, Email metadata like counters of email sent to and from the person and a label indicating whether a person is a POI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\ss842p\\\\Documents\\\\ATT Sab Documents\\\\Nano Degree\\\\Data Analyst\\\\Machine Learning\\\\ud120-projects-master\\\\ud120-projects-master\\\\final_project'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir(r'C:\\Users\\ss842p\\Documents\\ATT Sab Documents\\Nano Degree\\Data Analyst\\Machine Learning\\ud120-projects-master\\ud120-projects-master\\final_project') \n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "sys.path.append(\"../tools/\")\n",
    "import matplotlib.pyplot\n",
    "import seaborn as sns\n",
    "import tester\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "#from tester import dump_classifier_and_data\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1b) Data Exploration\n",
    "\n",
    "Imported the data points and upon analyzing the same, below are the observations:   "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1) Total number of Enron Employees included in the dataset are :  146\n",
    "2) Total number of Features included in the dataset are :  21\n",
    "3) Examine the unique values of POI field :  [False  True]\n",
    "4) How many are classified as POI and non-POI?  POI =  18 & non-POI =  128\n",
    "\n",
    "Something to note here are:\n",
    "1) The data set comprises of very low POI as compared to non POI (as one would expect). This needs to be taken into account when the Evaluation metrics are selected.\n",
    "2) The Nan values is string rather than actual Nan and hence needs to be massaged to reflect the NULL value in order to better represent the shape of the data\n",
    "\n",
    "Outlier Analysis:\n",
    "The idea here is to look for outlier in the datapoint that is going to \n",
    "a) skew the results unfairly\n",
    "b) add to the noise and has no relevance to the outcome of the study\n",
    "\n",
    "From that perspective:\n",
    "1) There is the record with Aggregate Total i.e. \"TOTAL\" that needs to be removed from the dataset\n",
    "2) The financial data corresponding to the employees BELFER ROBERT & BHATNAGAR SANJAY did not tally with the provided column level aggregate of Salary and Stock and hence this needs to be cleaned up manaully by referencing the source PDF i.e. the metadata information from enron61702insiderpay.pdf      \n",
    "3) On checking the applicability of the information available for each employee, I see that LOCKHART EUGENE E has all of the financial and email related columns as NULL and furthere he is a non poi and hence this record would be scrubbed from the study\n",
    "4) Also, I see that there is a record related to the \"THE TRAVEL AGENCY IN THE PARK\". Although this is not related to any employee, I do not know enough about the impact of removing this from the dataset and hence I am not excluding this from the dataset at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************Data Exploration Analysis*******************************************\n",
      "Total number of Enron Employees included in the dataset are :  146\n",
      "Total number of Features included in the dataset are :  21\n",
      "Examine the unique values of POI field :  [False  True]\n",
      "How many are classified as POI and non-POI?  POI =  18 & non-POI =  128\n",
      "Do the dataset have any NaN Values? <class 'pandas.core.frame.DataFrame'>\n",
      "Index: 146 entries, ALLEN PHILLIP K to YEAP SOON\n",
      "Data columns (total 21 columns):\n",
      "salary                       146 non-null object\n",
      "to_messages                  146 non-null object\n",
      "deferral_payments            146 non-null object\n",
      "total_payments               146 non-null object\n",
      "exercised_stock_options      146 non-null object\n",
      "bonus                        146 non-null object\n",
      "restricted_stock             146 non-null object\n",
      "shared_receipt_with_poi      146 non-null object\n",
      "restricted_stock_deferred    146 non-null object\n",
      "total_stock_value            146 non-null object\n",
      "expenses                     146 non-null object\n",
      "loan_advances                146 non-null object\n",
      "from_messages                146 non-null object\n",
      "other                        146 non-null object\n",
      "from_this_person_to_poi      146 non-null object\n",
      "poi                          146 non-null bool\n",
      "director_fees                146 non-null object\n",
      "deferred_income              146 non-null object\n",
      "long_term_incentive          146 non-null object\n",
      "email_address                146 non-null object\n",
      "from_poi_to_this_person      146 non-null object\n",
      "dtypes: bool(1), object(20)\n",
      "memory usage: 24.1+ KB\n",
      " None\n",
      "Checking specific column to double check if there is indeed no NaN :  Empty DataFrame\n",
      "Columns: [salary, to_messages, deferral_payments, total_payments, exercised_stock_options, bonus, restricted_stock, shared_receipt_with_poi, restricted_stock_deferred, total_stock_value, expenses, loan_advances, from_messages, other, from_this_person_to_poi, poi, director_fees, deferred_income, long_term_incentive, email_address, from_poi_to_this_person]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the data onto a data frame for analysis and wrangling as needed:\n",
    "\n",
    "enron_df = pd.DataFrame.from_dict(data_dict, orient = 'index')\n",
    "enron_feature_list = list(enron_df.columns.values)\n",
    "    \n",
    "print \"****************Data Exploration Analysis*******************************************\"\n",
    "print \"Total number of Enron Employees included in the dataset are : \", enron_df.shape[0]\n",
    "print \"Total number of Features included in the dataset are : \", enron_df.shape[1]\n",
    "print \"Examine the unique values of POI field : \", enron_df.poi.unique()\n",
    "print \"How many are classified as POI and non-POI? \", \"POI = \",enron_df[enron_df[\"poi\"]==1].shape[0], \"& non-POI = \",enron_df[enron_df[\"poi\"]==0].shape[0]\n",
    "print \"Do the dataset have any NaN Values? \", enron_df.info() \n",
    "print \"Checking specific column to double check if there is indeed no NaN : \",enron_df[enron_df[\"salary\"].isnull()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************** Data Wrangling *******************************************\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 146 entries, ALLEN PHILLIP K to YEAP SOON\n",
      "Data columns (total 21 columns):\n",
      "salary                       95 non-null float64\n",
      "to_messages                  86 non-null float64\n",
      "deferral_payments            39 non-null float64\n",
      "total_payments               125 non-null float64\n",
      "exercised_stock_options      102 non-null float64\n",
      "bonus                        82 non-null float64\n",
      "restricted_stock             110 non-null float64\n",
      "shared_receipt_with_poi      86 non-null float64\n",
      "restricted_stock_deferred    18 non-null float64\n",
      "total_stock_value            126 non-null float64\n",
      "expenses                     95 non-null float64\n",
      "loan_advances                4 non-null float64\n",
      "from_messages                86 non-null float64\n",
      "other                        93 non-null float64\n",
      "from_this_person_to_poi      86 non-null float64\n",
      "poi                          146 non-null bool\n",
      "director_fees                17 non-null float64\n",
      "deferred_income              49 non-null float64\n",
      "long_term_incentive          66 non-null float64\n",
      "email_address                111 non-null object\n",
      "from_poi_to_this_person      86 non-null float64\n",
      "dtypes: bool(1), float64(19), object(1)\n",
      "memory usage: 24.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print \"**************** Data Wrangling *******************************************\"\n",
    "# Replace 'NaN' with the numpy nan\n",
    "enron_df = enron_df.replace('NaN', np.nan) \n",
    "#display(enron_df.info())\n",
    "print enron_df.info()\n",
    "\n",
    "# Replacing the numpy.nan to 'NaN' as the feature format function scrubs the NaN (string) from the numerical field \n",
    "# handled in the following funtion -> featureFormat( dictionary, features, remove_NaN=True, remove_all_zeroes=True, remove_any_zeroes=False, sort_keys = False):\n",
    "# pdata_dict = pdata_dict.replace(np.nan,'NaN')\n",
    "# print data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleansing #1 = Outlier Detection\n",
    "Analyze the data deeper and with context in order to understand if there is any outlier that may affect the study undesirably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preparation(pdata_dict,features):\n",
    "    # leveraging the function provided by udacity - from feature_format import featureFormat, targetFeatureSplit\n",
    "    data = featureFormat(data_dict, features) \n",
    "    return data\n",
    "\n",
    "def outlier_detection(data): \n",
    "    max_val = []\n",
    "    max_xval = 0\n",
    "    max_yval = 0\n",
    "    for point in data:\n",
    "        if point[0] > max_xval:\n",
    "            max_xval = point[0]\n",
    "        if point[1] > max_yval:\n",
    "            max_yval = point[1]            \n",
    "        matplotlib.pyplot.scatter( point[0], point[1] )\n",
    "    print \" Max of \",features[0],\" is \",max_xval\n",
    "    print \" Max of \",features[1],\" is \",max_yval\n",
    "    max_val.append(max_xval)\n",
    "    max_val.append(max_yval)\n",
    "    matplotlib.pyplot.xlabel(features[0])\n",
    "    matplotlib.pyplot.ylabel(features[1])\n",
    "    print matplotlib.pyplot.show()\n",
    "    return max_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************** Before Outlier removal******************************************\n",
      " Max of  salary  is  26704229.0\n",
      " Max of  bonus  is  97343619.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bad4908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print \"***************** Before Outlier removal******************************************\"\n",
    "features = [\"salary\", \"bonus\"]\n",
    "data = data_preparation(data_dict,features)\n",
    "#print data\n",
    "max_val = outlier_detection(data)\n",
    "#print max_val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The above record corresponds to Total line and this needs to be scrubbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           salary  to_messages  deferral_payments  total_payments  \\\n",
      "TOTAL  26704229.0          NaN         32083396.0     309886585.0   \n",
      "\n",
      "       exercised_stock_options       bonus  restricted_stock  \\\n",
      "TOTAL              311764000.0  97343619.0       130322299.0   \n",
      "\n",
      "       shared_receipt_with_poi  restricted_stock_deferred  total_stock_value  \\\n",
      "TOTAL                      NaN                 -7576788.0        434509511.0   \n",
      "\n",
      "                ...            loan_advances  from_messages       other  \\\n",
      "TOTAL           ...               83925000.0            NaN  42667589.0   \n",
      "\n",
      "       from_this_person_to_poi    poi  director_fees  deferred_income  \\\n",
      "TOTAL                      NaN  False      1398517.0      -27992891.0   \n",
      "\n",
      "       long_term_incentive  email_address from_poi_to_this_person  \n",
      "TOTAL           48521928.0            NaN                     NaN  \n",
      "\n",
      "[1 rows x 21 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bonus': 97343619,\n",
       " 'deferral_payments': 32083396,\n",
       " 'deferred_income': -27992891,\n",
       " 'director_fees': 1398517,\n",
       " 'email_address': 'NaN',\n",
       " 'exercised_stock_options': 311764000,\n",
       " 'expenses': 5235198,\n",
       " 'from_messages': 'NaN',\n",
       " 'from_poi_to_this_person': 'NaN',\n",
       " 'from_this_person_to_poi': 'NaN',\n",
       " 'loan_advances': 83925000,\n",
       " 'long_term_incentive': 48521928,\n",
       " 'other': 42667589,\n",
       " 'poi': False,\n",
       " 'restricted_stock': 130322299,\n",
       " 'restricted_stock_deferred': -7576788,\n",
       " 'salary': 26704229,\n",
       " 'shared_receipt_with_poi': 'NaN',\n",
       " 'to_messages': 'NaN',\n",
       " 'total_payments': 309886585,\n",
       " 'total_stock_value': 434509511}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the Total line from the Data Frame\n",
    "print enron_df[enron_df.salary == max_val[0]]\n",
    "#display(enron_df[enron_df.salary == max_val[0]])\n",
    "# create a new df after reoving the Total line\n",
    "enron_df = enron_df[enron_df.salary != max_val[0]]\n",
    "#enron_df = enron_df[enron_df.loc != 'TOTAL']\n",
    "\n",
    "# Remove the Total line from the data dictionary\n",
    "# hardcoded the value to remove from the data_dict. I have done this intentionally \n",
    "# This was done so as not to remove the Top data point accidentallu for every execution which may remove the POI record\n",
    "data_dict.pop('TOTAL',0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************** After Outlier removal******************************************\n",
      " Max of  salary  is  1111258.0\n",
      " Max of  bonus  is  8000000.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAEKCAYAAAC7c+rvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3XmcFeWd7/HPr3fWZpcGJIjiFiUuHcExJFESQY2DEzVDbmYgjrnkZSaL3jETHG+Mo5PR3HivxpvExMkmuSaEURMg6iDTkglxQRsxrQjI4kJDYzdbs/b+u3/Uc5rTzenltH26uunv+/U6r1P1q6fqecpD+pen6ql6zN0RERGJQ1bcDRARkf5LSUhERGKjJCQiIrFREhIRkdgoCYmISGyUhEREJDZKQiIiEhslIRERiY2SkIiIxCYn7gb0dqNGjfJJkybF3QwRkT5l7dq1u919dEfllIQ6MGnSJEpLS+NuhohIn2Jm73SmnC7HiYhIbJSEREQkNkpCIiISGyUhERGJjZKQiIjERklIRERik9EkZGa3mNl6M3vdzH5tZgVmdoqZrTGzzWb2GzPLC2Xzw/qWsH1S0nFuC/FNZjYrKT47xLaY2cKkeNp1SN92eF0lFfe+RPnC1VTc+xKH11XG3SQR6YSMJSEzGw98FSh293OAbGAu8B3gfnefAuwDbgy73Ajsc/fTgPtDOczs7LDfB4HZwA/NLNvMsoEfAFcAZwOfDWVJtw7p2w6vq2T/E5tp3F8LQOP+WvY/sVmJSKQPyPTluBxggJnlAAOBCuAy4LGw/RHgmrA8J6wTts80Mwvxxe5e6+5vAVuAi8Jni7tvc/c6YDEwJ+yTbh3Shx1Y8TZe39Qi5vVNHFjxdjwNEpFOy1gScvcdwH3Au0TJpxpYC+x394ZQrBwYH5bHA9vDvg2h/MjkeKt92oqP7EIdLZjZAjMrNbPSqqqqrpy+9KBED6izcRHpPTJ5OW44Uc/jFGAcMIjo0llrntiljW3dFW+vjpYB94fdvdjdi0eP7vDVRxKz7GH5acVFpPfI5OW4TwBvuXuVu9cDTwB/AQwLl+cAJgA7w3I5cDJA2F4I7E2Ot9qnrfjuLtQhfdjQWZOw3Jb/lC03i6GzJsXTIBHptEwmoXeB6WY2MNx3mQm8AawCrgtl5gNLw/KysE7Y/qy7e4jPDSPbTgGmAC8BLwNTwki4PKLBC8vCPunWIX3YoPPHMOzTU5p7PtnD8hn26SkMOn9MzC0TkY5k7C3a7r7GzB4DXgEagHXAw8CTwGIz+5cQ+2nY5afAL81sC1HvZG44znozW0KUwBqAv3f3RgAz+zKwgmjk3c/cfX041jfSqUP6vkHnj1HSEemDTB2B9hUXF7umchARSY+ZrXX34o7K6Y0JIiISGyUhERGJjZKQiIjERklIRERioyQkIiKxURISEZHYKAmJiEhslIRERCQ2SkIiIhIbJSEREYmNkpCIiMRGSUhERGKjJCQiIrFREhIRkdgoCYmISGwyloTM7AwzezXpc8DMbjazEWa20sw2h+/hobyZ2YNmtsXMyszsgqRjzQ/lN5vZ/KT4hWb2WtjnwTCDK12pQ0REel7GkpC7b3L389z9POBC4AjwW2AhUOLuU4CSsA5wBdHU3VOABcBDECUU4FvANOAi4FuJpBLKLEjab3aIp1WHiMgJqWwJ3H8O3Dks+i5bEneLjtNTl+NmAlvd/R1gDvBIiD8CXBOW5wCLPPIiMMzMioBZwEp33+vu+4CVwOywbai7v+DR9LCLWh0rnTpERE4sZUtg+Vehejvg0ffyr/a6RNRTSWgu8OuwfJK7VwCE7zEhPh7YnrRPeYi1Fy9PEe9KHSIiJ5aSu6D+aMtY/dEo3otkPAmZWR7wl8C/d1Q0Rcy7EO9KHS0LmS0ws1IzK62qqurgkCIivVB1eXrxmPRET+gK4BV3fy+sv5e4BBa+K0O8HDg5ab8JwM4O4hNSxLtSRwvu/rC7F7t78ejRo9M4VRGRXqJwQnrxmPREEvosxy7FASwDEiPc5gNLk+Lzwgi26UB1uJS2ArjczIaHAQmXAyvCtoNmNj2MipvX6ljp1CEicmKZeQfkDmgZyx0QxXuRnEwe3MwGAp8EvpgUvhdYYmY3Au8C14f4U8CVwBaikXQ3ALj7XjO7G3g5lLvL3feG5ZuAXwADgKfDJ+06REROOFM/E32X3BVdgiucECWgRLyXsGhgmbSluLjYS0tL426GiEifYmZr3b24o3J6Y4KIiMRGSUhERGKjJCQiIrFREhIRkdgoCYmISGyUhEREJDZKQiIiEhslIRERiY2SkIiIxEZJSEREYqMkJCIisVESEhGR2CgJiYhIbJSEREQkNkpCIiISm4wmITMbZmaPmdlGM9tgZheb2QgzW2lmm8P38FDWzOxBM9tiZmVmdkHSceaH8pvNbH5S/EIzey3s82CYYZWu1CEiIj0v0z2h7wH/4e5nAh8CNgALgRJ3nwKUhHWAK4Ap4bMAeAiihAJ8C5gGXAR8K5FUQpkFSfvNDvG06hARkXhkLAmZ2VDgo8BPAdy9zt33A3OAR0KxR4BrwvIcYJFHXgSGmVkRMAtY6e573X0fsBKYHbYNdfcXPJoedlGrY6VTh4iIxCCTPaHJQBXwczNbZ2Y/MbNBwEnuXgEQvseE8uOB7Un7l4dYe/HyFHG6UIeIiMQgk0koB7gAeMjdzwcOc+yyWCqWIuZdiLenU/uY2QIzKzWz0qqqqg4OKSIiXZXJJFQOlLv7mrD+GFFSei9xCSx8VyaVPzlp/wnAzg7iE1LE6UIdLbj7w+5e7O7Fo0eP7vQJi4hIejKWhNx9F7DdzM4IoZnAG8AyIDHCbT6wNCwvA+aFEWzTgepwKW0FcLmZDQ8DEi4HVoRtB81sehgVN6/VsdKpQ0REYpCT4eN/BXjUzPKAbcANRIlviZndCLwLXB/KPgVcCWwBjoSyuPteM7sbeDmUu8vd94blm4BfAAOAp8MH4N506hARkXhYNLBM2lJcXOylpaVxN0NEpE8xs7XuXtxROb0xQUREYqMkJCIiVC9fzubLZrLhrLPZfNlMqpcv75F6M31PSEREernq5cup+OYdeE0NAA07d1LxzTsAKLz66ozWrZ6QiEg/V3n/A80JKMFraqi8/4GM160kJCLSzzVUpH5Spa14d1ISEhHp53KKUr9Cs614d1ISEhHp58bccjNWUNAiZgUFjLnl5ozXrYEJIiL9XGLwQeX9D9BQUUFOURFjbrk544MSQElIRESIElFPJJ3WdDlORERioyQk70tcD7iJyIlBl+Oky+J8wE1ETgzqCUmXxfmAm4icGJSEpMvifMBNRE4MSkLSZXE+4CYiJ4aMJiEze9vMXjOzV82sNMRGmNlKM9scvoeHuJnZg2a2xczKzOyCpOPMD+U3m9n8pPiF4fhbwr7W1TokfXE+4CYiJ4ae6Ald6u7nJU1utBAocfcpQElYB7gCmBI+C4CHIEoowLeAacBFwLcSSSWUWZC03+yu1CFdU3j11RTdfRc548aBGTnjxlF0910alCAinRbH6Lg5wMfD8iPAH4BvhPgij6Z6fdHMhplZUSi7MjGlt5mtBGab2R+Aoe7+QogvAq4hmuI7rTrcXTcxuiiuB9xE5MSQ6Z6QA8+Y2VozWxBiJyX+6IfvMSE+HtietG95iLUXL08R70odIiISg0z3hC5x951mNgZYaWYb2ylrKWLehXh7OrVPSJgLACZOnNjBIUVEpKsy2hNy953huxL4LdE9nffCZTbCd2UoXg6cnLT7BGBnB/EJKeJ0oY7W7X7Y3YvdvXj06NHpnLKIiKQhY0nIzAaZ2ZDEMnA58DqwDEiMcJsPLA3Ly4B5YQTbdKA6XEpbAVxuZsPDgITLgRVh20Ezmx5Gxc1rdax06hARkRhk8nLcScBvw6jpHOBX7v4fZvYysMTMbgTeBa4P5Z8CrgS2AEeAGwDcfa+Z3Q28HMrdlRikANwE/AIYQDQg4ekQvzedOkREJB4WDRSTthQXF3tpaWnczRAR6VPMbG3Sozlt0hsTREQkNkpCIiISGyUhERGJjZKQiIjERklIRERioyQkIiKxURISEZHYKAmJiEhsOpWEzOz6pFfw/E8ze0ITwomIyPvV2Z7QN939oJl9BJhFNEePJoQTEZH3pbNJqDF8XwU85O5LgbzMNElERPqLziahHWb2Y+AzwFNmlp/GviIiIil1NpF8hmhKhdnuvh8YAXw9Y62SXu3xXXspfn49Ratepfj59Ty+a2/HO4mIpNDZqRxGAaUAZpaYarS9WVLlBPX4rr3cumk7R5uit6+X19Zz66ZoxvRrx46Is2ki0gd1Ngk9ybEptQuAU4BNwAcz1C7ppe7ZVtGcgBKONjn3bKtQEhKRtHUqCbn7ucnrYXj2FzPSIunVdtTWpxUXEWlPlwYXuPsrwIc7U9bMss1snZn9PqyfYmZrzGyzmf3GzPJCPD+sbwnbJyUd47YQ32Rms5Lis0Nsi5ktTIqnXYd0zvj83LTiIiLt6ezDqv8j6XOrmf0KqOpkHV8DNiStfwe4392nAPuAG0P8RmCfu58G3B/KYWZnA3OJLv3NBn4YEls28APgCuBs4LOhbNp1SOfdNrmIAVnWIjYgy7htclFMLRKRvqyzPaEhSZ98ontEczraycwmED1b9JOwbsBlwGOhyCPANWF5TlgnbJ8Zys8BFrt7rbu/BWwBLgqfLe6+zd3rgMXAnC7WIZ107dgR3HfGyUzIz8WACfm53HfGybofJCJd0tl7Qv/cxeM/APwjUfICGAnsd/eGsF4OjA/L44Htob4GM6sO5ccDLyYdM3mf7a3i07pYx+7kRpvZAmABwMSJE5GWrh07QklHRLpFp5KQmZ0O3ApMSt7H3S9rZ59PAZXuvtbMPp4IpyjqHWxrK56qF9de+Y7qPxZwfxh4GKC4uPi47SIi0j06O0T734EfEV1Wa+ygbMIlwF+a2ZVEw7qHEvWMhplZTuipTAB2hvLlwMlAuZnlAIXA3qR4QvI+qeK7u1CHiIjEoLP3hBrc/SF3f8nd1yY+7e3g7re5+wR3n0Q0sOBZd/8csAq4LhSbDywNy8vCOmH7s+7uIT43jGw7BZgCvAS8DEwJI+HyQh3Lwj7p1iEiIjHobE9ouZl9CfgtUJsIuntXehHfABab2b8A64CfhvhPgV+a2Rai3sncUMd6M1sCvAE0AH/v7o0AZvZlotcJZQM/c/f1XalDRETiYZ3pCJjZWynC7u6Tu79JvUtxcbGXlpbG3QwRkT7FzNa6e3FH5To7Ou6U998kERGRljo7Oi4XuAn4aAj9Afixu+tdLSIi0mWdvSf0EJAL/DCs/22IfSETjRIRkf6hs0now+7+oaT1Z83sz5lokIiI9B+dnt7bzE5NrJjZZDr/vJCIiEhKne0JfR1YZWbbwvok4IaMtEhERPqNzvaEngN+DDSFz4+BFzLVKBER6R862xNaBBwA7g7rnwV+CVyfiUaJiEj/0NkkdEargQmrNDBBRETer85ejltnZtMTK2Y2jegSnYiISJe12xMys9eIpjrIBeaZ2bth/QNE73ITERHpso4ux32qR1ohIiL9UrtJyN3f6amGiIhI/9PZgQkiGXF4XSUHVrxN4/5asoflM3TWJAadPybuZolID1ESktgcXlfJ/ic24/VNADTur2X/E5sBlIhE+onOjo5Lm5kVmNlLZvZnM1tvZv8c4qeY2Roz22xmvwmzohJmTv2NmW0J2yclHeu2EN9kZrOS4rNDbIuZLUyKp12H9LwDK95uTkAJXt/EgRVvd2s9FbuW8txzMyh59jSee24GFbuWdrxTDzm8rpKKe1+ifOFqKu59icPrKuNukkiPylgSIpqB9bLwfNF5wOwwzPs7wP3uPgXYB9wYyt8I7HP304D7QznM7GyiGVA/CMwGfmhm2WaWDfwAuAI4G/hsKEu6dUg8GvfXphXviopdS9m48XZqancCTk3tTjZuvL1XJKJETzBxvomeoBKR9CcZS0IeORRWc8PHgcuAx0L8EeCasDwnrBO2zzQzC/HF7l7r7m8BW4CLwmeLu29z9zpgMTAn7JNuHRKD7GH5acW7YtvW+2hqOtoi1tR0lG1b7+u2Orqqp3qCIr1ZJntChB7Lq0AlsBLYCux394ZQpBwYH5bHA9sBwvZqYGRyvNU+bcVHdqGO1u1eYGalZlZaVVXVtZOXDg2dNQnLbflP0HKzGDprUrfVUVNbkVa8J/VET1Ckt8toEnL3Rnc/D5hA1HM5K1Wx8J2qR+LdGG+vjpYB94fdvdjdi0ePHp1iF+kOg84fw7BPT2nu+WQPy2fYp6d066CEgvyitOI9qSd6giK9XY+MjnP3/Wb2B2A6MMzMckJPZAKwMxQrB04Gys0sBygE9ibFE5L3SRXf3YU6JCaDzh+T0ZFwk0+9lY0bb29xSS4rawCTT701Y3V21tBZk1qMDoTu7wmK9HaZHB032syGheUBwCeADcAq4LpQbD6QuEO8LKwTtj/r7h7ic8PItlOAKcBLwMvAlDASLo9o8MKysE+6dcgJqmjsHM4889sU5I8DjIL8cZx55rcpGjsn7qb1SE9QpLezTP0NNrOpRIMAsomS3RJ3vyvMyroYGAGsA/7G3WvNrIBoeojziXonc919WzjW7cDfAQ3Aze7+dIhfCTwQ6viZu387xNOuoy3FxcVeWlraXf9ZRET6BTNb6+7FHZZTR6B9SkIiIunrbBLK6MAEERGR9ui1PdJvbFi9itWLF3Fwz26GjBzFjLnzOGvGpXE3S6RfUxKSfmHD6lU88/D3aaiLnsE5uLuKZx7+PoASkUiMlISk13tzzS5eWLqVQ3trGTwin4vnnMrp08amdYzVixc1J6CEhrpaVi9epCQkEiMlIenV3lyzi1WPbqShLnqW5tDeWlY9uhEgrUR0cM/utOIi0jM0MEF6tReWbm1OQAkNdU28sHRrWscZMnJUWnER6RlKQtKrHdqb+j1qbcXbMmPuPHLyWr4OJycvnxlz53W5bSLy/ulynPRqg0fkp0w4g0ek9361xH0fjY4T6V2UhKRXu3jOqS3uCQHk5GVx8ZxT0z7WWTMuVdIR6WWUhKRXSww+eL+j40Skd1ISkl7v9GljlXRETlAamCAiIrFREhIRkdgoCYmISGyUhEREJDaZnFn1ZDNbZWYbzGy9mX0txEeY2Uoz2xy+h4e4mdmDZrbFzMrM7IKkY80P5Teb2fyk+IVm9lrY50Ezs67WISIiPS+To+MagH9w91fMbAiw1sxWAp8HStz9XjNbCCwEvgFcQTR19xRgGvAQMM3MRgDfAooBD8dZ5u77QpkFwIvAU8Bs4OlwzE7XkcH/BtINysrKKCkpobq6msLCQmbOnMnUqVPjbpZI71S2BErugupyKJwAM++AqZ+Ju1VtylhPyN0r3P2VsHwQ2ACMB+YQTftN+L4mLM8BFnnkRWCYmRUBs4CV7r43JJ6VwOywbai7v+DR9LCLWh0rnTqklyorK2P58uVUV1cDUF1dzfLlyykrK4u5ZSK9UNkSWP5VqN4OePS9/KtRvJfqkXtCZjYJOB9YA5zk7hUQJSpgTCg2HtietFt5iLUXL08Rpwt1SC9VUlJCfX19i1h9fT0lJSUxtUikFyu5C+qPtozVH43ivVTGk5CZDQYeB2529wPtFU0R8y7E221OZ/YxswVmVmpmpVVVVR0cUjIp0QPqbFykX6suTy/eC2Q0CZlZLlECetTdnwjh9xKXwMJ3ZYiXAycn7T4B2NlBfEKKeFfqaMHdH3b3YncvHj16dOdPWLpdYWFhWnGRfq1wQnrxXiCTo+MM+Cmwwd3/T9KmZUBihNt8YGlSfF4YwTYdqA6X0lYAl5vZ8DDK7XJgRdh20Mymh7rmtTpWOnVILzVz5kxyc3NbxHJzc5k5c2ZMLRLpxWbeAbkDWsZyB0TxXiqTo+MuAf4WeM3MXg2xfwLuBZaY2Y3Au8D1YdtTwJXAFuAIcAOAu+81s7uBl0O5u9x9b1i+CfgFMIBoVNzTIZ5WHdJ7JUbBxTU6rmLXUrZtvY+a2goK8ouYfOqtFI2d0yN1i6QtMQquD42Os2hgmbSluLjYS0tL425Gr1W9fDmV9z9AQ0UFOUVFjLnlZgqvvjruZnWLil1L2bjxdpqajt3ozcoawJlnfluJSKQDZrbW3Ys7Kqc3JkiXVS9fTsU376Bh505wp2HnTiq+eQfVy5fH3bRusW3rfS0SEEBT01G2bb0vphaJnHiUhKTLKu9/AK+paRHzmhoq738gphZ1r5ra1LcL24qLSPqUhKTLGipS/zFuK97XFOSnfo65rbiIpE9JSLospyj1H+O24n3N5FNvJSur5UijrKwBTD711phaJHLiURKSLhtzy81YQUGLmBUUMOaWm5vXq5cvZ/NlM9lw1tlsvmxmn7pfVDR2Dmee+W0K8sfhQHVjDo9UNTL/Tz/gyW1Pxt08kROCpveWLkuMgmtrdFxi4ELivlFi4ELyvr1d0dg5vHIkhzufv5OaxsT9rwrufP5OAK6afFVsbRM5EWiIdgc0RLvrNl82Mxo510rOuHFMebbvvPvt8scup+Lw8fe5igYV8cx1z8TQIpHer7NDtNUTkoxJZ+DC47v2cs+2CnbU1jM+P5fbJhdx7dgRmW5ip+w6vCutuIh0npKQZExOUVHqnlCrgQuP79rLrZu2c7Qp6pWX19Zz66boZee9IRGNHTT2uJ7Qx6uLuXH3pylfuJrsYfkMnTWJQeePaeMIItIWDUyQjOnMwAWAe7ZVNCeghKNNzj3besdQ769d8DUKso+dx8eri/laxd8wqm4YAI37a9n/xGYOr6ts6xAi0gb1hCRj3vnAB1j5mes5WFvLwCNHOO/d7Uz7m88dNyhhR219yv3bive0xOCD773yPXYd3sWNuz9Ngee1KOP1TRxY8bZ6QyJpUk9IMiIxI+rBujow48igQbw89Vze+cAHkgotgfvPYXxN6nsr4+uqes2MkFdNvopnrnuGsvllzT2g1hr31/Zwq0T6PiUhyYgOZ0RNmob4tm0PM6Cx5et/BjTWcNuWh7p9auKKXUt57rkZlDx7Gs89N4OKXUs73qmV7GH5acVFpG26HCcZ0dbMp/ur9zP1kamMbWzia3nGVfVwbVWUmO6ZvIAd+WMYX1vJbdsebo5Tctf7ehV9WVkZJSUl5OWt4/Qz1pCV1QBATe1ONm68HSCtt2IPnTWJ/U9sxuubmmOWm8XQWZO63EaR/kpJSDKisLAwZSI6kn0Ex6nINu4cFY18u+rwEa6tKjmWdFp7H1MTJy4L1tfX8+GLXm1OQAmJt2Knk4QS930OrHibxv21Gh0n8j5kcmbVn5lZpZm9nhQbYWYrzWxz+B4e4mZmD5rZFjMrM7MLkvaZH8pvNrP5SfELzey1sM+DYXbVLtUh3S/VjKgN1sDrw5v/OVCTlcX3hqe+v9LC+5iaOPmyYH7+4ZRluvJW7EHnj6Fo4UVMuHcGRQsvUgIS6aJM9oR+AXwfWJQUWwiUuPu9ZrYwrH8DuAKYEj7TgIeAaWY2AvgWUAw4sNbMlrn7vlBmAfAi0Yyps4lmVk2rjoydfT/R1kOmrWdEPZx9mNeHv075kJa9moqcHIrHT+Si9SM4b3ceM07azllDkpLC+5yaOLk3Vls7iIKC4xNR8luxD6+rbO7h/OcA58dWy64jdYwbNoCvzzqDa84f3+W2iMjxMpaE3P2PZjapVXgO8PGw/AjwB6IEMQdY5NE7hF40s2FmVhTKrkxM521mK4HZZvYHYKi7vxDii4BriJJQWnW4e+94GKUP6ugh06lTpzYno7ZefYNBbR78aepeKBvJ0V1nQH4hZ+Vt6papiZMvC7791nlMOf1FsrMbm7cnvxX78LrK5ns9z1DHd47WkBjvtmP/UW574jUAJSKRbtTTo+NOSvzRD9+Jaxjjge1J5cpDrL14eYp4V+qQLkrnIdPWD3y25tnwyhn7aWhoZHX12XDnfrjl9Q4T0OO79lL8/HqKVr1K8fPreXzX3hbbky8LVlVNZvOb06mtGQQYBfnjWkzVfWDF282DDX5MLa0HXB+tb+S7Kza12x4RSU9vGZhgKWLehXhX6ji+oNkCokt9TJw4sYPD9l9tPUx6zluHqfjjSy1u2tcUXUz9qC/g730/5Q8BcHhA1EM5uGd3p+rvqCe2YfUqXly8iKy6RrLHTqQxO4e6uvOZMOHW5h5asuTnfCrb+Oe0c//RlHER6Zqe7gm9Fy6zEb4T7zkpB05OKjcB2NlBfEKKeFfqOI67P+zuxe5ePHr06LROsD8Zn597XGzWzjr+5xu1zX/QG/fXsvvxN/mPZ7eyK38aTdkj2zzeqPpokMKQkaM6VX97PbENq1fxzMPf5+DuKvIO7GXgm68yfOtrzC4+L2UCgpbP+YxpI1WOGzYgZVxEuqank9AyIDHCbT6wNCk+L4xgmw5Uh0tpK4DLzWx4GOV2ObAibDtoZtPDqLh5rY6VTh3SRbdNLmJA1rE/1h98p5bbymooaGxZLrvBWfBmlJQOF15PTlP2cceyJqMuq55fXPEOiz78Ct9ZfsZxD5P+bt0OLrn3WU5Z+CSX3Pss5e287mf14kU01LW8oNZQV8vqxYtS7gPR8z+WG/1P4ovk0/rR0wG52Xx91hlt7t8Zrc/hd+t2vK/jifR1GbscZ2a/JhogMMrMyolGud0LLDGzG4F3getD8aeAK4EtwBHgBgB332tmdwMvh3J3JQYpADcRjcAbQDQg4ekQT6sO6bpz36njH586QGN1PUfzjPx6Z9DQ1P+kTqqJeiy1gy/h7zYcYvHI33IgOxqplt+UR6M1ciAnWq+mid/sywXeo64+eph0TUUxtz3xGkfrowy3Y/9R7GgDPuD4+sbn57Z5Sa+9S33Jz/9cvh+yBuR26+i4363bcdw5aLCD9Hea1K4DmtQutTfX7GLVoxtpqGtqEf/kkBwGZh9/KasiF67NPkxuXilzsispOlLEYWoZ7AUsm/h79uUe/2Dr8OwmvjWuhoL8cTy4dC5nlq9mSOMhDmYP5vnh09gw5UM0fnAYnnOsQ1/gTfzvsyex5+5/4ODuquOOOWTUaBb84Ofd8F8gfZfc+yxOgnDGAAASr0lEQVQ7UtxTGj9sAM8tvCyGFolkTmcntdO746RLXli69bgEBPBGTSMNx/0fmxpKG14lq6aRKQNfZWDNUA5bLRgcyqphX07qV/zsa4yS2c7XD3H+uysZ2ngIA4Y2HmLmnv/irM1/Jmf9Pk7aU4V5EyftqeLrv/0V144dwYy588jJa3lBLScvnxlz53XH6XdJW4MaNNhB+rPeMjpO+phDe1O/MXpHvcORRs4uyGZAFtR4I+Py/i9vjLmAmtMu5tWC2ymraeDL6x/lS4cfo5CDHC0bx1V/gpEHYM9Q+NXHjec+mM3w7CiZ7Xq5iFxv+bqdXG/gL/atoXrbKB750b8e22AG3MdZMy4FYPXiRRzcXcXh3CH8aehFLHnO+frgHbFc/ho3bEDKnpAGO0h/piQkaXtzTfvTWu+od3bUN5BDDZcO/SH/ctI5/PtZfwnZUcd7zoE/cPPRXzGQWqrfHsC8l52s0OsZfQC++JSTQyMnz2ggK2sAdQdTd9iHNB5i/vqnW8SSZ209a8albBp8Ovcn3YchxvswX591Rot7QtA9gx1E+jJdjpO0vbB0a5vb8u0Q0MTgrEouHfpDTh+4ml+e+unmBATwT2/9GwObop5UZdmQ5gSUUNAAN/yxiY+MOIkzz/w2Q0alHiaf1ZTFZTvWNa+nmrX1uys2tfijD/E9dHrN+eO559PnMn7YAIzoXtA9nz5XgxKkX1NPSDplw+pV0aWtPbvBBpNT8BFy8s86rtwXbqqB5Qug/ihPDhrIl4ePo6Gg5fNE42uPTYPdcOT44doAA6uzuPCS1QDMmDuUZx7+fosh1zl5+Xzkw5eQs+cwDRUV5BQVMeaWm4+btbW33Ye55vzxSjoiSZSEpEOJBz+bk4AfpOHISoAWiWjwiPzm1+w8ufou7hzo1GRlkXu0gfqBxxLRjvwxnFz7XrT/wEYajhz/z7D1ZTU4dn8nb0gTYz+8jZpzKhn3mVvbnYZB92FEejclIelQqgc/oYGGmj81JyHLruPMjx8NPaanObD7A9x0qJozd+1l2OF5VA4fxb9d89eUXPQR/vWU/87/fvO7DGyqZczUg1S8XIg3Hrtc15Sff9xltbNmXMqwKQfYuPF2mpqipFJTe6DDSel0H0akd1MSkuM8ue1JvvfK99h1eBdjB41l1u685m2bBp3GC8OnczBnMEMaDvHRunqm5lYz+tzfsv3tbZT/sYjG+gbG7T3EueV7yQnDtU/at5tb/9+/gTvPnnMZv7Yarm94hKGTdrMnt5CqskEMrj5C5YiRLLpmLp/68CVc26pd27be15yAEjqalC5x6eu7Kzaxc/9RTckg0ssoCUkLT257kjufv5OaxhoABr09Ds86ijUdZtOg03h21MdpyIourR3MHcLK/CMUnf0Yp41by/pHT6WxPhpKfcauYwkooaC+jn/49a954eIPUsMl/CLrQrZPeI0XZp7Nlv92couyr22r4NqxI1rE2pp8rqNJ6XQfRqT3UhKSFr73yveaE9BpVRfysW1zsYKtNBxZyQvDpzcnoIS6pjx+u+VqLh63lvpDx7YNqD/2XM87EydS9qGpHBk4kIFHjpBd/x4DDw/nrDd+zV+8+Aanf+hDPDLrr9hy0rFElOoN3QX5RdTUHv/O2eRJ6aR7JQ9IGTJyFDPmzmu+RyfSHTREW1rYdfjYM0DT3v0UuU155OSfRc7AT3IwZ3DKffbUDAcgd/CxxHE0N/r/N+9MnMjLF32YI4MGgRlHBg3i0NA3Gb5/KUWVpQw6coTpL73EZ0uWtzjmmD1VbL5sJtXLj8Unn3orWVktBxQkT0on3Sv5TeS4c3B3Fc88/H02rF4Vd9PkBKIkJC2MHTS2eXlw3fDm5Zz8sxjalPqfy+iafRR9KZcz3tlHdngeaNPYETSYUfahqTTmtOxwe5bz7qRjCS2nsZFpa9c2r+fX1vKFpYtp2LmTim/e0ZyIisbO4cwzv01B/jhSTUon3asrbyIXSZcux0kLX7vga833hA7l7WNI3bH7MjNqclgxsJ6GpGdL8xvq+PxrT2MYE8sPkVO7m7LJE9k5Ao5m5XNk4MCU9bSODzxyBHNnzN7dfGHpYj7x8vMAeE0Nlfc/0Pz8T9HYOUo6PaQrbyIXSZeSUF9StgRK7oLqciicADPv6HD66856fNde7tlWwY7a8YyY+BAD9y9hzcTf87Ftc8ltikbHnV2fQ+PRBlYNPkRt00DG1B5kftnyFm8tGFe1j9uKv0Jl/lAArvM/M9jqjqtv4JEjLdaPFhRS8qX/lnIquYYKTfsUhyEjR6V+E3knJx0U6Qwlob6ibAks/yrUhyHK1dujdXjfiaj1NNl7GnM4Uvg59n/gh8Bipr37KQbXDedQ3j7em/h78kaX8rPThjPiC3sgjIBLHnzwUX+LtQ3jeatpFGsbxnNJ7jvk2LE3bmc3NDD1z2XN6w1Zuew853pOe2s57HnvuPYlP7gqPWfG3Hkp31QR55vI5cTT75KQmc0GvgdkAz9x93tjblLnlNx1LAEl1B+N4u8zCbU1TXbu8LlsOfJVtoxe22Lb8OxokMChogdp2LmzefBB4t7PYKvjktx3oB7eahoF9XBhzg4GZdUxrLCQi4cPZ+TzL9BgRk5REeNuuZlzr76a6uWnU/HNO/Camua6Ur0PTnpGizdVaHScZEi/SkJmlg38APgkUA68bGbL3P2NTNT3u3U7WPL4Js7Z08RQzyJncA6XXX86p08b2/HOwZtrdvHC0q3Myy2PZikIDjd8jAMN82msGUX2P/2WoVk/Z1DOf8GAEXDFd45LTGVlZZSUlFBdXU1hYSEzZ85k6tSpAEysKeFWHmUUe9jNSJbwOZ63j1KfNYz5T03kcEEja8/Yx1vjj5BnsODs6ykaO4fqW7Ko+OYdKQcf5FgT07Lf5q2mUbzVNIpdfhL3zEl6WefnP3/cuSbu+1Te/0C774PrSMWupWzbeh81tRUU5Bcx+dT2X+0jbTtrxqVKOpJR/SoJARcBW9x9G4CZLQbmAN2ehH63bgc/+9V6LjuYTW4YhNh4qIH//OUGgE4louTZSw+OGsXQnOj6/OGGj7G/4Ss4BdFxm0axv+krAAw6+l/wuy9FBwiJqKysjOXLl1NfHw2hrq6uZnkYcTZ6zFv8d35EHtEll9Hs5gv8CBxeP3QuhjG4JodLXhvJsPzh/PVffYWrJl8FREnj3Xff5UjlsReSJivIauL0g29y+OQPdfotBYVXX5120klWsWtpq1f77Ozw1T4iEp/+NkR7PLA9ab08xLrdd1dsYvqhLHJb3Wr3Bm93KoRkybOXvnjocxwNxzrQML85ATUflwIONMyPVprqo8t0QUlJSXMCSqivr6ekpIRtW+9rTkAJ+dTy1/4oM9asbI7lNGXxkW1FzQko4T/r6mjRRUti9XVcRxnPLbysx95Y0N6rfUSk9+lvSSjVX8vWc1FjZgvMrNTMSquqjh8d1Bk79x9lqKf+49zWrKTtldtc8zHuHDWcndnZNJJ6dFKLeHX5scXq1NNnV1dXt/nKm5Hs5uwtZS1iqYbmNh+7qeWcPTQ1kle1o8eH83b11T4iEo/+loTKgeSXlE0AjnsPjLs/7O7F7l48enTqCdU6Mm7YAA7YcfkNCFMedELrcn/MPZlZE8fzXs6+lOWzSfqDXzjh2GJhYcryhYWFbb7ypv7Q8VdqUw3NTRw7770dWF0tuGN1teRXvEPegb09Ppy3rfPRq31Eeqf+loReBqaY2SlmlgfMBZZloqKvzzqDFwc3Ud+qo2U5xsVzTu3UMS6ecyo5ecd+omnvfoqcxlx+MWYpNdayN2XUMDTnkWglKzd6hiiYOXMmubkt3/mWm5vLzJkzU74Kx8jjvbXjWsTaGpqbOHbTwEEM2raeIRvXMnjra+Qd2BvLcF692kekb+lXAxPcvcHMvgysIBqi/TN3X5+JuhL3QN7P6LhEuReWbuXQ3lrO90s4Z8J4lhx4hAf5FX+3+68YWVdITtaedkfHJUbBpR4dF207bjRZ7lBW7+l4aG7ysQ8DA3ZXQF0NQ0aNjmU4b2LwgUbHifQN5p76kpFEiouLvbS0NO5miIj0KWa21t2LOyrX3y7HiYhIL6IkJCIisVESEhGR2CgJiYhIbJSEREQkNkpCIiISGyUhERGJjZKQiIjERg+rdsDMqoB33udhRgE9+ybPnqHz6lt0Xn1LXz+vD7h7hy/fVBLqAWZW2pknh/sanVffovPqW07U82pNl+NERCQ2SkIiIhIbJaGe8XDcDcgQnVffovPqW07U82pB94RERCQ26gmJiEhslIQyyMxmm9kmM9tiZgvjbg+AmZ1sZqvMbIOZrTezr4X4CDNbaWabw/fwEDczezCcQ5mZXZB0rPmh/GYzm58Uv9DMXgv7PGhm1l4d3Xx+2Wa2zsx+H9ZPMbM1oc7fhBl1MbP8sL4lbJ+UdIzbQnyTmc1Kiqf8Pduqo5vPa5iZPWZmG8Nvd/GJ8JuZ2S3h3+HrZvZrMyvoi7+Zmf3MzCrN7PWkWGy/T3t19Drurk8GPkQzt24FJgN5wJ+Bs3tBu4qAC8LyEOBN4GzgfwELQ3wh8J2wfCXwNGDAdGBNiI8AtoXv4WF5eNj2EnBx2Odp4IoQT1lHN5/f/wB+Bfw+rC8B5oblHwE3heUvAT8Ky3OB34Tls8NvlQ+cEn7D7PZ+z7bq6ObzegT4QljOA4b19d8MGA+8BQxI+u/4+b74mwEfBS4AXk+Kxfb7tFVHb/zE3oAT9RP+waxIWr8NuC3udqVo51Lgk8AmoCjEioBNYfnHwGeTym8K2z8L/Dgp/uMQKwI2JsWby7VVRzeeywSgBLgM+H34H+BuIKf1b0I0xfvFYTknlLPWv1OiXFu/Z3t1dON5DSX6Y22t4n36NyNKQtvDH92c8JvN6qu/GTCJlkkott+nrTq6899ld310OS5zEv8DSygPsV4jXM44H1gDnOTuFQDhe0wo1tZ5tBcvTxGnnTq6ywPAPwJNYX0ksN/dG1K0pbn9YXt1KJ/u+bZXR3eZDFQBP7foUuNPzGwQffw3c/cdwH3Au0AF0W+wlhPjN4N4f59e//cnQUkocyxFrNcMRTSzwcDjwM3ufqC9oili3oV4RpnZp4BKd1+bHG6nLd11Xj1xvjlEl3oecvfzgcNEl17a0hvP4Tjh/sUcokto44BBwBXttKUv/Wbt6Yn2xn2OnaYklDnlwMlJ6xOAnTG1pQUzyyVKQI+6+xMh/J6ZFYXtRUBliLd1Hu3FJ6SIt1dHd7gE+EszextYTHRJ7gFgmJnlpGhLc/vD9kJgbwfnlSq+u506uks5UO7ua8L6Y0RJqa//Zp8A3nL3KnevB54A/oIT4zeDeH+fXvv3pzUlocx5GZgSRuHkEd1IXRZzmwijan4KbHD3/5O0aRmQGI0zn+heUSI+L4y2mQ5Uh27/CuByMxse/h/t5UTX1SuAg2Y2PdQ1r9WxUtXxvrn7be4+wd0nEf23ftbdPwesAq5r47wSbbkulPcQnxtGYp0CTCG6KZzy9wz7tFVHd53bLmC7mZ0RQjOBN+jjvxnRZbjpZjYw1Js4rz7/m6Vob0//Pm3V0fvEfVPqRP4QjVB5k2iEzu1xtye06SNE3fIy4NXwuZLoOnkJsDl8jwjlDfhBOIfXgOKkY/0dsCV8bkiKFwOvh32+z7GHolPWkYFz/DjHRsdNJvqDtAX4dyA/xAvC+pawfXLS/reHtm8ijEJq7/dsq45uPqfzgNLwu/2OaPRUn//NgH8GNoa6f0k0wq3P/WbAr4nua9UT9UJujPP3aa+O3vbRGxNERCQ2uhwnIiKxURISEZHYKAmJiEhslIRERCQ2SkIiIhIbJSGRPsTMfmFm13VcUqRvUBISOYElvRVApFfSP1CRmIWXkS4herVKNnA3cAZwNTAAeB74ord6qM/M7khVxsz+ENYvAZ41s88Dp7t7vZkNJXrgdYpHr8oRiZV6QiLxmw3sdPcPufs5wH8A33f3D4f1AcCnUuzXXplh7v4xd/9n4A/AVSE+F3hcCUh6CyUhkfi9BnzCzL5jZjPcvRq41KKZP18jehnrB1Ps116Z3yQt/wS4ISzfAPy8+09BpGt0OU4kZu7+ppldSPSes3vM7Bng74ne97XdzO4kem9aMzMrAH7YTpnDScd/zswmmdnHgGx3fx2RXkI9IZGYmdk44Ii7/z+iSd4uCJt2h3mfUo2GK+hEmWSLiF6yqV6Q9CrqCYnE71zgu2bWRPQW5puAa4gu071NNCVBC+6+38z+rb0yrTwK/AtRIhLpNfQWbZF+IDxbNMfd/zbutogkU09I5ARnZv+XaNrsK+Nui0hr6gmJiEhsNDBBRERioyQkIiKxURISEZHYKAmJiEhslIRERCQ2SkIiIhKb/w/MC+gDaxNbnwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bbd39e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "[1111258.0, 8000000.0]\n",
      "                       salary  to_messages  deferral_payments  total_payments  \\\n",
      "SKILLING JEFFREY K  1111258.0       3627.0                NaN       8682716.0   \n",
      "\n",
      "                    exercised_stock_options      bonus  restricted_stock  \\\n",
      "SKILLING JEFFREY K               19250000.0  5600000.0         6843672.0   \n",
      "\n",
      "                    shared_receipt_with_poi  restricted_stock_deferred  \\\n",
      "SKILLING JEFFREY K                   2042.0                        NaN   \n",
      "\n",
      "                    total_stock_value           ...            loan_advances  \\\n",
      "SKILLING JEFFREY K         26093672.0           ...                      NaN   \n",
      "\n",
      "                    from_messages    other  from_this_person_to_poi   poi  \\\n",
      "SKILLING JEFFREY K          108.0  22122.0                     30.0  True   \n",
      "\n",
      "                    director_fees  deferred_income  long_term_incentive  \\\n",
      "SKILLING JEFFREY K            NaN              NaN            1920000.0   \n",
      "\n",
      "                              email_address from_poi_to_this_person  \n",
      "SKILLING JEFFREY K  jeff.skilling@enron.com                    88.0  \n",
      "\n",
      "[1 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Double check if there are any other data points that may be skewing the data set unfairly\n",
    "print \"***************** After Outlier removal******************************************\"\n",
    "features = [\"salary\", \"bonus\"]\n",
    "data = data_preparation(data_dict,features)\n",
    "max_val = outlier_detection(data)\n",
    "print max_val\n",
    "print enron_df[enron_df.salary == max_val[0]]\n",
    "#display(enron_df[enron_df.salary == max_val[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference after Outlier Removal\n",
    "After the Total line removal, the data set looks good with the new Top Salary corresponding to SKILLING JEFFREY K who is a POI.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleansing #2 = Anomaly Detection\n",
    "There is also Column level aggregation in Total_Payments and Total_Stock_Values  in the dataset. The Payment related fields tallies to the Total_Payment and likewise the stock related fields tallies upto Total_Stock_Values for each Key present in the datapoint (source: the metadata information from enron61702insiderpay.pdf). These fields could be used for validating the accuracy of the data points that is used for the current study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional scrubbing\n",
    "\n",
    "def detect_anomaly():\n",
    "    # Create 4 separate list to orgranize 4 groups of data i.e. payment, stock, email and poi\n",
    "    # Create payment dataframe\n",
    "    enron_payment_df = enron_df.loc[:,\n",
    "                                      ['salary','bonus','long_term_incentive',\n",
    "                                      'deferred_income','deferral_payments','loan_advances',\n",
    "                                      'other','expenses','director_fees','total_payments']]\n",
    "\n",
    "\n",
    "    # Create stock dataframe\n",
    "    enron_stock_df = enron_df.loc[:,\n",
    "                                      ['exercised_stock_options','restricted_stock','restricted_stock_deferred','total_stock_value']]\n",
    "\n",
    "    # Creating finance list + poi. The objective is to do a delta from the parent enron_df and extract email related information in a data frame\n",
    "    enron_finan_list = enron_payment_df.columns.values.tolist() + enron_stock_df.columns.values.tolist() + [\"poi\"]\n",
    "    s = set(enron_finan_list)\n",
    "\n",
    "    # Create email dataframe\n",
    "    enron_email_list = [x for x in enron_df.columns.values.tolist() if x not in s]\n",
    "    enron_email_df = enron_df.loc[:,enron_email_list]\n",
    "\n",
    "    # Rearranging the columns\n",
    "    enron_email_df = enron_email_df[['email_address','from_messages','to_messages','from_this_person_to_poi','from_poi_to_this_person','shared_receipt_with_poi']]\n",
    "    \n",
    "    #Create poi dataframe\n",
    "    enron_poi_df = enron_df.loc[:,[\"poi\"]] \n",
    "    \n",
    "    print \n",
    "    print \"*********************************************************************************************************\"\n",
    "    print \"Data with values not aligned with the Column level aggregation in Total_Payments and Total_Stock_Values \"\n",
    "    print \"*********************************************************************************************************\"\n",
    "    # Validate if the payment & stock data tallies up to their corresponding Columnar total available in the dataset\n",
    "    #display(enron_payment_df[enron_payment_df.iloc[:,0:9].fillna(0).sum(axis=1) != enron_payment_df.iloc[:,9].fillna(0)])\n",
    "    #display(enron_stock_df[enron_stock_df.iloc[:,0:3].fillna(0).sum(axis=1) != enron_stock_df.iloc[:,3].fillna(0)])\n",
    "    print enron_payment_df[enron_payment_df.iloc[:,0:9].fillna(0).sum(axis=1) != enron_payment_df.iloc[:,9].fillna(0)]\n",
    "    print enron_stock_df[enron_stock_df.iloc[:,0:3].fillna(0).sum(axis=1) != enron_stock_df.iloc[:,3].fillna(0)]\n",
    "    #print enron_stock_df.iloc[:,0:3].fillna(0)\n",
    "    #print enron_stock_df.iloc[:,3].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*********************************************************************************************************\n",
      "Data with values not aligned with the Column level aggregation in Total_Payments and Total_Stock_Values \n",
      "*********************************************************************************************************\n",
      "                  salary  bonus  long_term_incentive  deferred_income  \\\n",
      "BELFER ROBERT        NaN    NaN                  NaN              NaN   \n",
      "BHATNAGAR SANJAY     NaN    NaN                  NaN              NaN   \n",
      "\n",
      "                  deferral_payments  loan_advances     other  expenses  \\\n",
      "BELFER ROBERT             -102500.0            NaN       NaN       NaN   \n",
      "BHATNAGAR SANJAY                NaN            NaN  137864.0       NaN   \n",
      "\n",
      "                  director_fees  total_payments  \n",
      "BELFER ROBERT            3285.0        102500.0  \n",
      "BHATNAGAR SANJAY       137864.0      15456290.0  \n",
      "                  exercised_stock_options  restricted_stock  \\\n",
      "BELFER ROBERT                      3285.0               NaN   \n",
      "BHATNAGAR SANJAY                2604490.0        -2604490.0   \n",
      "\n",
      "                  restricted_stock_deferred  total_stock_value  \n",
      "BELFER ROBERT                       44093.0           -44093.0  \n",
      "BHATNAGAR SANJAY                 15456290.0                NaN  \n"
     ]
    }
   ],
   "source": [
    "detect_anomaly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up Anomaly\n",
    "\n",
    "The 2 records when further compared to the pdf file source: enron61702insiderpay.pdf), it looks like the values are mismatched. This is likely a data entry error and I will fix them in my dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Fix the anomaly detected above from the Data Frame. \n",
    "This data frame will be type casted into data dictionary for the ML alogirthme\n",
    "'''\n",
    "# Clean up BELFER ROBERT\n",
    "enron_df.at['BELFER ROBERT','deferred_income'] = -102500.0\n",
    "enron_df.at['BELFER ROBERT','deferral_payments'] = np.nan\n",
    "enron_df.at['BELFER ROBERT','expenses'] = 3285.0\n",
    "enron_df.at['BELFER ROBERT','director_fees'] = 102500.0\n",
    "enron_df.at['BELFER ROBERT','total_payments'] = 3285.0\n",
    "\n",
    "enron_df.at['BELFER ROBERT','exercised_stock_options'] = np.nan\n",
    "enron_df.at['BELFER ROBERT','restricted_stock'] = 44093.0\n",
    "enron_df.at['BELFER ROBERT','restricted_stock_deferred'] =-44093.0\n",
    "enron_df.at['BELFER ROBERT','total_stock_value'] = np.nan\n",
    "\n",
    "enron_df.loc['BELFER ROBERT']\n",
    "\n",
    "# Clean up BHATNAGAR SANJAY\n",
    "\n",
    "enron_df.at['BHATNAGAR SANJAY','other'] = np.nan\n",
    "enron_df.at['BHATNAGAR SANJAY','expenses'] = 137864.0\n",
    "enron_df.at['BHATNAGAR SANJAY','director_fees'] = np.nan\n",
    "enron_df.at['BHATNAGAR SANJAY','total_payments'] = 137864.0\n",
    "\n",
    "enron_df.at['BHATNAGAR SANJAY','exercised_stock_options'] = 15456290.0\n",
    "enron_df.at['BHATNAGAR SANJAY','restricted_stock'] = 2604490.0\n",
    "enron_df.at['BHATNAGAR SANJAY','restricted_stock_deferred'] =-2604490.0\n",
    "enron_df.at['BHATNAGAR SANJAY','total_stock_value'] = 15456290.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*********************************************************************************************************\n",
      "Data with values not aligned with the Column level aggregation in Total_Payments and Total_Stock_Values \n",
      "*********************************************************************************************************\n",
      "Empty DataFrame\n",
      "Columns: [salary, bonus, long_term_incentive, deferred_income, deferral_payments, loan_advances, other, expenses, director_fees, total_payments]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [exercised_stock_options, restricted_stock, restricted_stock_deferred, total_stock_value]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check now to see if the anomalies are addressed\n",
    "detect_anomaly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleansing #3 = Missing Value Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*********************************************************************************************************\n",
      "Validate the # of columns with NULL values for each record / key \n",
      "*********************************************************************************************************\n",
      "LOCKHART EUGENE E                20\n",
      "WROBEL BRUCE                     18\n",
      "WHALEY DAVID A                   18\n",
      "GRAMM WENDY L                    18\n",
      "THE TRAVEL AGENCY IN THE PARK    18\n",
      "GILLIS JOHN                      17\n",
      "WODRASKA JOHN                    17\n",
      "SAVAGE FRANK                     17\n",
      "SCRIMSHAW MATTHEW                17\n",
      "CLINE KENNETH W                  17\n",
      "WAKEHAM JOHN                     17\n",
      "CHAN RONNIE                      16\n",
      "MENDELSOHN JOHN                  16\n",
      "PEREIRA PAULO V. FERRAZ          16\n",
      "BLAKE JR. NORMAN P               16\n",
      "YEAP SOON                        16\n",
      "GATHMANN WILLIAM D               16\n",
      "URQUHART JOHN A                  16\n",
      "FUGH JOHN L                      16\n",
      "LOWRY CHARLES P                  16\n",
      "MEYER JEROME J                   16\n",
      "WINOKUR JR. HERBERT S            16\n",
      "CHRISTODOULOU DIOMEDES           16\n",
      "NOLES JAMES L                    15\n",
      "LEMAISTRE CHARLES                15\n",
      "WALTERS GARETH W                 15\n",
      "GRAY RODNEY                      15\n",
      "BADUM JAMES P                    15\n",
      "DUNCAN JOHN H                    15\n",
      "BELFER ROBERT                    14\n",
      "                                 ..\n",
      "THORN TERENCE H                   5\n",
      "SKILLING JEFFREY K                5\n",
      "SHELBY REX                        5\n",
      "SHANKMAN JEFFREY A                5\n",
      "MURRAY JULIA H                    5\n",
      "DURAN WILLIAM D                   5\n",
      "MCCONNELL MICHAEL S               5\n",
      "MCMAHON JEFFREY                   5\n",
      "FALLON JAMES B                    5\n",
      "FITZGERALD JAY L                  5\n",
      "KOENIG MARK E                     5\n",
      "KEAN STEVEN J                     5\n",
      "GARLAND C KEVIN                   5\n",
      "GLISAN JR BEN F                   5\n",
      "LAVORATO JOHN J                   5\n",
      "RIEKER PAULA H                    4\n",
      "BELDEN TIMOTHY N                  4\n",
      "SHARP VICTORIA T                  4\n",
      "RICE KENNETH D                    4\n",
      "WASAFF GEORGE                     4\n",
      "OLSON CINDY K                     4\n",
      "HANNON KEVIN P                    4\n",
      "MULLER MARK S                     4\n",
      "BUY RICHARD B                     4\n",
      "PIPER GREGORY F                   3\n",
      "DERRICK JR. JAMES V               3\n",
      "LAY KENNETH L                     2\n",
      "HAEDICKE MARK E                   2\n",
      "FREVERT MARK A                    2\n",
      "ALLEN PHILLIP K                   2\n",
      "Length: 145, dtype: int64\n",
      "                               salary  to_messages  deferral_payments  \\\n",
      "LOCKHART EUGENE E                 NaN          NaN                NaN   \n",
      "WROBEL BRUCE                      NaN          NaN                NaN   \n",
      "WHALEY DAVID A                    NaN          NaN                NaN   \n",
      "GRAMM WENDY L                     NaN          NaN                NaN   \n",
      "THE TRAVEL AGENCY IN THE PARK     NaN          NaN                NaN   \n",
      "\n",
      "                               total_payments  exercised_stock_options  bonus  \\\n",
      "LOCKHART EUGENE E                         NaN                      NaN    NaN   \n",
      "WROBEL BRUCE                              NaN                 139130.0    NaN   \n",
      "WHALEY DAVID A                            NaN                  98718.0    NaN   \n",
      "GRAMM WENDY L                        119292.0                      NaN    NaN   \n",
      "THE TRAVEL AGENCY IN THE PARK        362096.0                      NaN    NaN   \n",
      "\n",
      "                               restricted_stock  shared_receipt_with_poi  \\\n",
      "LOCKHART EUGENE E                           NaN                      NaN   \n",
      "WROBEL BRUCE                                NaN                      NaN   \n",
      "WHALEY DAVID A                              NaN                      NaN   \n",
      "GRAMM WENDY L                               NaN                      NaN   \n",
      "THE TRAVEL AGENCY IN THE PARK               NaN                      NaN   \n",
      "\n",
      "                               restricted_stock_deferred  total_stock_value  \\\n",
      "LOCKHART EUGENE E                                    NaN                NaN   \n",
      "WROBEL BRUCE                                         NaN           139130.0   \n",
      "WHALEY DAVID A                                       NaN            98718.0   \n",
      "GRAMM WENDY L                                        NaN                NaN   \n",
      "THE TRAVEL AGENCY IN THE PARK                        NaN                NaN   \n",
      "\n",
      "                                        ...            loan_advances  \\\n",
      "LOCKHART EUGENE E                       ...                      NaN   \n",
      "WROBEL BRUCE                            ...                      NaN   \n",
      "WHALEY DAVID A                          ...                      NaN   \n",
      "GRAMM WENDY L                           ...                      NaN   \n",
      "THE TRAVEL AGENCY IN THE PARK           ...                      NaN   \n",
      "\n",
      "                               from_messages     other  \\\n",
      "LOCKHART EUGENE E                        NaN       NaN   \n",
      "WROBEL BRUCE                             NaN       NaN   \n",
      "WHALEY DAVID A                           NaN       NaN   \n",
      "GRAMM WENDY L                            NaN       NaN   \n",
      "THE TRAVEL AGENCY IN THE PARK            NaN  362096.0   \n",
      "\n",
      "                               from_this_person_to_poi    poi  director_fees  \\\n",
      "LOCKHART EUGENE E                                  NaN  False            NaN   \n",
      "WROBEL BRUCE                                       NaN  False            NaN   \n",
      "WHALEY DAVID A                                     NaN  False            NaN   \n",
      "GRAMM WENDY L                                      NaN  False       119292.0   \n",
      "THE TRAVEL AGENCY IN THE PARK                      NaN  False            NaN   \n",
      "\n",
      "                               deferred_income  long_term_incentive  \\\n",
      "LOCKHART EUGENE E                          NaN                  NaN   \n",
      "WROBEL BRUCE                               NaN                  NaN   \n",
      "WHALEY DAVID A                             NaN                  NaN   \n",
      "GRAMM WENDY L                              NaN                  NaN   \n",
      "THE TRAVEL AGENCY IN THE PARK              NaN                  NaN   \n",
      "\n",
      "                               email_address from_poi_to_this_person  \n",
      "LOCKHART EUGENE E                        NaN                     NaN  \n",
      "WROBEL BRUCE                             NaN                     NaN  \n",
      "WHALEY DAVID A                           NaN                     NaN  \n",
      "GRAMM WENDY L                            NaN                     NaN  \n",
      "THE TRAVEL AGENCY IN THE PARK            NaN                     NaN  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Validate if there are any records with lots of NULL values that may not be useful\n",
    "print\n",
    "print \"*********************************************************************************************************\"\n",
    "print \"Validate the # of columns with NULL values for each record / key \"\n",
    "print \"*********************************************************************************************************\"\n",
    "\n",
    "print enron_df.isnull().sum(axis=1).sort_values(ascending=False)\n",
    "print enron_df.loc[['LOCKHART EUGENE E','WROBEL BRUCE','WHALEY DAVID A','GRAMM WENDY L','THE TRAVEL AGENCY IN THE PARK']]\n",
    "\n",
    "# LOCKHART EUGENE E has all of the financial and email related columns as NULL and furthere he is a non poi and hence could be scrubbed from the study\n",
    "try:\n",
    "    enron_df = enron_df.drop('LOCKHART EUGENE E')\n",
    "except ValueError:\n",
    "    pass    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Feature Selection \n",
    "\n",
    "a) My plan is to initially use all the features (except the email address) as is and build 3 models based on GaussianNB, Decision Tree Classifier and KMeans respectively and to arrive at the evaluation. This will server as the baseline for performance of the algorithm.\n",
    "\n",
    "b) The next step would be to engineer new features and to determine K Best features based on their relevance to the output labels that are to be predicted.\n",
    "\n",
    "c) The third and final step is to pick the better performing algorithm from above steps and tuning the hyperparameters to improve the results as needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2a) Feature Selection - Performance Baseline\n",
    "The idea is to use all of the existing features except email and determine the performance to serve as a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list_org_all = ['poi','salary', 'to_messages', 'deferral_payments', 'total_payments', 'exercised_stock_options', 'bonus',\n",
    " 'restricted_stock', 'shared_receipt_with_poi', 'restricted_stock_deferred', 'total_stock_value', 'expenses',\n",
    " 'loan_advances', 'from_messages', 'other', 'from_this_person_to_poi', 'director_fees', 'deferred_income',\n",
    " 'long_term_incentive',\n",
    " 'from_poi_to_this_person']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing the numpy.nan to 'NaN' as the feature format function scrubs the NaN (string) from the numerical field \n",
    "# handled in the following funtion -> featureFormat( dictionary, features, remove_NaN=True, remove_all_zeroes=True, remove_any_zeroes=False, sort_keys = False):\n",
    "enron_df = enron_df.replace(np.nan,'NaN')\n",
    "my_dataset = enron_df.to_dict('index')\n",
    "\n",
    "# Resetting the 'Nan' back to numpy.nan in enron_df\n",
    "enron_df = enron_df.replace('NaN', np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*********************************************************************************************************\n",
      "Model Evaluation - Baseline Performance before any New engineered features / Feature Selection / Tuning\n",
      "*********************************************************************************************************\n",
      "GaussianNB(priors=None)\n",
      "\tAccuracy: 0.76980\tPrecision: 0.25448\tRecall: 0.37650\tF1: 0.30369\tF2: 0.34355\n",
      "\tTotal predictions: 15000\tTrue positives:  753\tFalse positives: 2206\tFalse negatives: 1247\tTrue negatives: 10794\n",
      "\n",
      "*********************************************************************************************************\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "\tAccuracy: 0.80033\tPrecision: 0.23467\tRecall: 0.22000\tF1: 0.22710\tF2: 0.22278\n",
      "\tTotal predictions: 15000\tTrue positives:  440\tFalse positives: 1435\tFalse negatives: 1560\tTrue negatives: 11565\n",
      "\n",
      "*********************************************************************************************************\n",
      "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
      "    n_clusters=2, n_init=10, n_jobs=1, precompute_distances='auto',\n",
      "    random_state=None, tol=0.0001, verbose=0)\n",
      "\tAccuracy: 0.83447\tPrecision: 0.23017\tRecall: 0.10300\tF1: 0.14231\tF2: 0.11580\n",
      "\tTotal predictions: 15000\tTrue positives:  206\tFalse positives:  689\tFalse negatives: 1794\tTrue negatives: 12311\n",
      "\n",
      "*********************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "print \n",
    "print \"*********************************************************************************************************\"\n",
    "print \"Model Evaluation - Baseline Performance before any New engineered features / Feature Selection / Tuning\"\n",
    "print \"*********************************************************************************************************\"\n",
    "\n",
    "#data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "#labels, features = targetFeatureSplit(data)\n",
    "\n",
    "\n",
    "# Create and test the Gaussian Naive Bayes Classifier\n",
    "clf = GaussianNB()\n",
    "tester.dump_classifier_and_data(clf, my_dataset, features_list_org_all)\n",
    "tester.main();\n",
    "\n",
    "print \"*********************************************************************************************************\"\n",
    "\n",
    "# Create and test the Decision Tree Classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "tester.dump_classifier_and_data(clf, my_dataset, features_list_org_all)\n",
    "tester.main();\n",
    "\n",
    "print \"*********************************************************************************************************\"\n",
    "\n",
    "# Create and test the K Means clustering classifier\n",
    "clf = KMeans(n_clusters=2)\n",
    "tester.dump_classifier_and_data(clf, my_dataset, features_list_org_all)\n",
    "tester.main();\n",
    "\n",
    "print \"*********************************************************************************************************\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2b) Feature Selection - Engineer new Features:\n",
    "The choice of new features are \n",
    "(a) ratio of financial earnings (total earning, payments, stock) as they may be good indicator for identifying POI\n",
    "(b) ratio of email exchanges that the employee had with the POI. The thought process is that POI is more tightly knit group and may have had frequent email correspondences with each other.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the below 5 features:\n",
    "\n",
    "enron_df['ratio_of_total_earning']=(enron_df['total_payments'].fillna(0)+ enron_df['total_stock_value'] .fillna(0))/enron_df ['total_payments'].fillna(0.0).sum() + enron_df ['total_stock_value'].fillna(0.0).sum()\n",
    "enron_df['ratio_of_total_payments']=enron_df['total_payments'].fillna(0) /enron_df ['total_payments'].fillna(0.0).sum()\n",
    "enron_df['ratio_of_total_stock']=enron_df['total_stock_value'].fillna(0)/ enron_df ['total_stock_value'].fillna(0.0).sum()\n",
    "enron_df['ratio_from_poi'] = enron_df['from_poi_to_this_person'] / enron_df['to_messages']\n",
    "enron_df['ratio_to_poi'] = enron_df['from_this_person_to_poi'] / enron_df['from_messages']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list_eng_all = ['poi','salary', 'to_messages', 'deferral_payments', 'total_payments', 'exercised_stock_options', 'bonus',\n",
    " 'restricted_stock', 'shared_receipt_with_poi', 'restricted_stock_deferred', 'total_stock_value', 'expenses',\n",
    " 'loan_advances', 'from_messages', 'other', 'from_this_person_to_poi', 'director_fees', 'deferred_income',\n",
    " 'long_term_incentive',\n",
    " 'from_poi_to_this_person',\n",
    " 'ratio_of_total_earning',\n",
    " 'ratio_of_total_payments',\n",
    " 'ratio_of_total_stock',\n",
    " 'ratio_from_poi','ratio_to_poi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the nan to 'Nan' before converting the df to dict\n",
    "\n",
    "enron_df = enron_df.replace(np.nan,'NaN')\n",
    "my_dataset = enron_df.to_dict('index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2c) Feature Selection - SelectKBest\n",
    "\n",
    "I intend to use SelectKBestselection function. SelectKBest works by selecting the Top K features that have maximum influence on the target variable. It takes 2 inputs i.e. features and lables and takes the K features and evaluates the relevance of every feature using the score function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************************************************************\n",
      "Feature Selection with Engineered Features\n",
      "*********************************************************************************************************\n",
      "\n",
      "Total list of Features ['poi', 'salary', 'to_messages', 'deferral_payments', 'total_payments', 'exercised_stock_options', 'bonus', 'restricted_stock', 'shared_receipt_with_poi', 'restricted_stock_deferred', 'total_stock_value', 'expenses', 'loan_advances', 'from_messages', 'other', 'from_this_person_to_poi', 'director_fees', 'deferred_income', 'long_term_incentive', 'from_poi_to_this_person', 'ratio_of_total_earning', 'ratio_of_total_payments', 'ratio_of_total_stock', 'ratio_from_poi', 'ratio_to_poi']\n",
      "\n",
      "SelectKBest scores:  [(22.78210782973431, 'total_stock_value'), (22.782107829734304, 'ratio_of_total_stock'), (22.61053070687377, 'exercised_stock_options'), (21.06000170753657, 'bonus'), (18.575703268041785, 'salary'), (16.64170707046899, 'ratio_to_poi'), (11.561887713503024, 'deferred_income'), (10.072454529369441, 'long_term_incentive'), (9.380236796811587, 'total_payments'), (9.380236796811587, 'ratio_of_total_payments')]\n",
      "\n",
      "KBest Features ['poi', 'total_stock_value', 'ratio_of_total_stock', 'exercised_stock_options', 'bonus', 'salary', 'ratio_to_poi', 'deferred_income', 'long_term_incentive', 'total_payments', 'ratio_of_total_payments']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = featureFormat(my_dataset, features_list_eng_all, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "# Perform feature selection\n",
    "selector = SelectKBest(f_classif, k='all')\n",
    "selector.fit(features, labels)\n",
    "kbest_scores = sorted(zip(selector.scores_, features_list_eng_all[1:]), reverse=True)\n",
    "\n",
    "# picking Top 12 features for the ML alogorithm:\n",
    "\n",
    "POI_label = ['poi']\n",
    "#features_list_all = features_list\n",
    "features_list_kbest= POI_label + [(i[1]) for i in kbest_scores[0:10]]\n",
    "\n",
    "print \"*********************************************************************************************************\"\n",
    "print \"Feature Selection with Engineered Features\"\n",
    "print \"*********************************************************************************************************\"\n",
    "\n",
    "print\n",
    "print 'Total list of Features',features_list_eng_all\n",
    "\n",
    "print\n",
    "print 'SelectKBest scores: ', kbest_scores[0:10]\n",
    "print\n",
    "print 'KBest Features',features_list_kbest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2d) Feature Engineering & Feature selection using KBest Features - Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*********************************************************************************************************\n",
      "Model Evaluation - Performance with new engineered features / Feature Selection - Before any Tuning\n",
      "*********************************************************************************************************\n",
      "*********************************************************************************************************\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "\tAccuracy: 0.80680\tPrecision: 0.28033\tRecall: 0.28650\tF1: 0.28338\tF2: 0.28524\n",
      "\tTotal predictions: 15000\tTrue positives:  573\tFalse positives: 1471\tFalse negatives: 1427\tTrue negatives: 11529\n",
      "\n",
      "*********************************************************************************************************\n",
      "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
      "    n_clusters=2, n_init=10, n_jobs=1, precompute_distances='auto',\n",
      "    random_state=None, tol=0.0001, verbose=0)\n",
      "\tAccuracy: 0.84800\tPrecision: 0.25862\tRecall: 0.07500\tF1: 0.11628\tF2: 0.08741\n",
      "\tTotal predictions: 15000\tTrue positives:  150\tFalse positives:  430\tFalse negatives: 1850\tTrue negatives: 12570\n",
      "\n",
      "GaussianNB(priors=None)\n",
      "\tAccuracy: 0.85487\tPrecision: 0.44212\tRecall: 0.33800\tF1: 0.38311\tF2: 0.35471\n",
      "\tTotal predictions: 15000\tTrue positives:  676\tFalse positives:  853\tFalse negatives: 1324\tTrue negatives: 12147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print \n",
    "print \"*********************************************************************************************************\"\n",
    "print \"Model Evaluation - Performance with new engineered features / Feature Selection - Before any Tuning\"\n",
    "print \"*********************************************************************************************************\"\n",
    "\n",
    "\n",
    "print \"*********************************************************************************************************\"\n",
    "\n",
    "# Create and test the Decision Tree Classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "tester.dump_classifier_and_data(clf, my_dataset, features_list_kbest)\n",
    "tester.main();\n",
    "\n",
    "print \"*********************************************************************************************************\"\n",
    "\n",
    "# Create and test the K Means clustering classifier\n",
    "clf = KMeans(n_clusters=2)\n",
    "tester.dump_classifier_and_data(clf, my_dataset, features_list_kbest)\n",
    "tester.main();\n",
    "\n",
    "# Create and test the Gaussian Naive Bayes Classifier\n",
    "clf = GaussianNB()\n",
    "tester.dump_classifier_and_data(clf, my_dataset, features_list_kbest)\n",
    "tester.main();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  2) Feature Selection - Observations: \n",
    "By comparing the above results with the baseline performance below are the observations:\n",
    "1) Gaussian NB is clearly performing better \n",
    "2) Newly engineered features helped the classifier performance\n",
    "3) Also, selecting the K best festures and using them for the classification improved the F1 score in comparison to the baseline model evaluation.\n",
    "Kmeans model evaluated the least and hence I am proceeding with the GaussianNB and DecistionTreeClassifier based models and tune them further to arrive at a final model\t\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Feature Scaling & Algorithm Selection:\n",
    "Although the dataset consists of wide range of values particularly the financial data, featue scaling is more relevant to the algorithm such as Kmeans that use the Eucledian distance between two data point. For the algorithm that I chose to implement i.e. the Gaussian NB and DecisionTree Classifer this would not have much impact. Nonetheless, I am implementing Min Max feature scaling as I am looking to determine if this makes any difference to the evaluation metrics of the algorithm that I have chosen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Parameter Tuning & Validation:\n",
    "\n",
    "<U> Tuning:</U>\n",
    "Parameter tuning essentially is the process to maximize the models performance while striking a balanace between  overfitting and high variance.The tuning of the hyperparameters could be achieved in a manual way or in an automated manner. I chose the GridSearchCV route to tune the models that I had chosen based on the resuls from Feature Selection. The algorithm are namely: DecisionTreeClassifier and GaussianNB\n",
    "\n",
    "The essential idea is to contruct a pipleline of Scaler (MinMaxScaler()), PCA and Hyperparameters grid (in case of DecisionTreeClassifier) to tune different combinations of the models.\n",
    "\n",
    "<U> Validation:</U>\n",
    "Validation is necessary to ensure that the developed model is just as useful and applicable to the \"real world data\" not just with the data that was used to train the algorithm. For the current problem at hand, the data points is relatively a smaller set, thereyby it is beneficial to iteratively draw and split the test/train data and valdiate the model against the several folds of the data. This makes the StratifiedShuffleSplit a suitable validation strategy.\n",
    "\n",
    "I have used the startup code utility i.e. tester.test_classifier that was provided by udacity towards this putpose of evaluating the metrics. For my analysis purpose, i had reused the code from tester.test_classifier and created a local function called ptest_classifier The only change that I had done to the ptest_classifer function is to reduce the folds from 1000 to 10 to tradeoff execution time and speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Evaluation Metrics:\n",
    "\n",
    "Here the problem at hand is to classify or categorize based on the features if the employee in the dataset is a POI or a non POI. From the underlying data we have  POI =  18 & non-POI =  128. The observations are imbalanced. Hence for the model to accurately label a non-POI as non POI is not particularly useful as it a likely occurence. This rules out the Accuracy metric unsuitable for a the imbalanced classes such as our problem here.\n",
    "\n",
    "\n",
    "Precision is the ratio of total number of True Positive to the total number of True Positive + False Postives. This answers the question - if the algorithm predicts a person as POI, how likely that the person is really a POI.\n",
    "\n",
    "while Recall is the ratio of total number of True Positive to the total number of True Positive + False Negative. This answers the question - how many times the algorithm identified a POI correctly,  provided that the person is indeed a POI\n",
    "\n",
    "Precision and Recall are more insightful to our classification here as the measure of high accuracy of Non-Poi is not really helpful. Instead, the ability to classify a POI as a POI is more meaningful.\n",
    "\n",
    "For evaluating of my algorithm, I am going with the F1 score which is the harmonic measure of precision and recall and is mathematically computed as \n",
    "2 * ( ( precision * recall) / (precision + recall) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function is based on tester.test_classifier that is provided as a part of start up code. \n",
    "The only change I have done here is to keep the folds to 10 rather than 1000 to trade off the execution time\"\"\"\n",
    "\n",
    "def ptest_classifier(clf, dataset, feature_list, folds = 1000):\n",
    "\n",
    "    import sys\n",
    "    from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "    sys.path.append(\"../tools/\")\n",
    "    from feature_format import featureFormat, targetFeatureSplit\n",
    "    PERF_FORMAT_STRING = \"\\\n",
    "    \\tAccuracy: {:>0.{display_precision}f}\\tPrecision: {:>0.{display_precision}f}\\t\\\n",
    "    Recall: {:>0.{display_precision}f}\\tF1: {:>0.{display_precision}f}\\tF2: {:>0.{display_precision}f}\"\n",
    "    RESULTS_FORMAT_STRING = \"\\tTotal predictions: {:4d}\\tTrue positives: {:4d}\\tFalse positives: {:4d}\\\n",
    "    \\tFalse negatives: {:4d}\\tTrue negatives: {:4d}\"\n",
    "\n",
    "    data = featureFormat(dataset, feature_list, sort_keys = True)\n",
    "    labels, features = targetFeatureSplit(data)\n",
    "    #  class sklearn.cross_validation.StratifiedShuffleSplit\n",
    "    # (y, n_iter=10, test_size=0.1, train_size=None, random_state=None)\n",
    "    cv = StratifiedShuffleSplit(labels, folds, random_state = 42)\n",
    "\n",
    "    true_negatives = 0\n",
    "    false_negatives = 0\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    for train_idx, test_idx in cv: \n",
    "        features_train = []\n",
    "        features_test  = []\n",
    "        labels_train   = []\n",
    "        labels_test    = []\n",
    "        for ii in train_idx:\n",
    "            features_train.append( features[ii] )\n",
    "            labels_train.append( labels[ii] )\n",
    "        for jj in test_idx:\n",
    "            features_test.append( features[jj] )\n",
    "            labels_test.append( labels[jj] )\n",
    "        \n",
    "        ### fit the classifier using training set, and test on test set\n",
    "        clf.fit(features_train, labels_train)\n",
    "        predictions = clf.predict(features_test)\n",
    " \n",
    "        for prediction, truth in zip(predictions, labels_test):\n",
    "            if prediction == 0 and truth == 0:\n",
    "                true_negatives += 1\n",
    "            elif prediction == 0 and truth == 1:\n",
    "                false_negatives += 1\n",
    "            elif prediction == 1 and truth == 0:\n",
    "                false_positives += 1\n",
    "            elif prediction == 1 and truth == 1:\n",
    "                true_positives += 1\n",
    "            else:\n",
    "                print \"Warning: Found a predicted label not == 0 or 1.\"\n",
    "                print \"All predictions should take value 0 or 1.\"\n",
    "                print \"Evaluating performance for processed predictions:\"\n",
    "                break\n",
    "    try:\n",
    "        total_predictions = true_negatives + false_negatives + false_positives + true_positives\n",
    "        accuracy = 1.0*(true_positives + true_negatives)/total_predictions\n",
    "        precision = 1.0*true_positives/(true_positives+false_positives)\n",
    "        recall = 1.0*true_positives/(true_positives+false_negatives)\n",
    "        f1 = 2.0 * true_positives/(2*true_positives + false_positives+false_negatives)\n",
    "        f2 = (1+2.0*2.0) * precision*recall/(4*precision + recall)\n",
    "        print clf\n",
    "        print PERF_FORMAT_STRING.format(accuracy, precision, recall, f1, f2, display_precision = 5)\n",
    "        print RESULTS_FORMAT_STRING.format(total_predictions, true_positives, false_positives, false_negatives, true_negatives)\n",
    "        print \"\"\n",
    "        #print '*******************************'\n",
    "        #print clf.best_estimator_.feature_importances_\n",
    "        #print '*******************************'        \n",
    "        \n",
    "    except:\n",
    "        print \"Got a divide by zero when trying out:\", clf\n",
    "        print \"Precision or recall may be undefined due to a lack of true positive predicitons.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Tuning and Validation of GaussianNB model with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*********************************************************************************************************************************\n",
      "Model Evaluation - Performance with new engineered features / Feature Selection / Tuning using StratifiedShuffleSplit\n",
      "*********************************************************************************************************************************\n",
      "GaussianNB Model Evaluation - with MinMaxScaler,SelectKBest & PCA using StratifiedShuffleSplit\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('selector', SelectKBest(k=10, score_func=<function f_classif at 0x000000001A08E6D8>)), ('reducer', PCA(copy=True, iterated_power='auto', n_components=None, random_state=42,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('classifier', GaussianNB(priors=None))]),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid={'reducer__n_components': [1, 2, 6, 10], 'selector__k': [10, 15, 'all'], 'scaler': [None, MinMaxScaler(copy=True, feature_range=(0, 1))]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, scoring='f1', verbose=0)\n",
      "\tAccuracy: 0.84247\tPrecision: 0.36723\tRecall: 0.25100\tF1: 0.29819\tF2: 0.26796\n",
      "\tTotal predictions: 15000\tTrue positives:  502\tFalse positives:  865\tFalse negatives: 1498\tTrue negatives: 12135\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \n",
    "print \"*********************************************************************************************************************************\"\n",
    "print \"Model Evaluation - Performance with new engineered features / Feature Selection / Tuning using StratifiedShuffleSplit\"\n",
    "print \"*********************************************************************************************************************************\"\n",
    "\n",
    "\n",
    "print \"GaussianNB Model Evaluation - with MinMaxScaler,SelectKBest & PCA using StratifiedShuffleSplit\"\n",
    "\n",
    "pipe = Pipeline([\n",
    "        ('scaler', preprocessing.MinMaxScaler()),\n",
    "        ('selector', SelectKBest()),\n",
    "        ('reducer', PCA(random_state=42)),\n",
    "        ('classifier', GaussianNB())\n",
    "    ])\n",
    "\n",
    "param_grid = {\n",
    "    'scaler': [None, preprocessing.MinMaxScaler()],\n",
    "    'selector__k': [10, 15, 'all'],\n",
    "    'reducer__n_components': [1,2,6,10]\n",
    "}\n",
    "\n",
    "clf_gnb_grd = GridSearchCV(pipe, param_grid, scoring='f1')\n",
    "#ptest_classifier(clf_gnb_grd, my_dataset, features_list_all)\n",
    "tester.dump_classifier_and_data(clf_gnb_grd, my_dataset, features_list_eng_all)\n",
    "tester.main();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Tuning and Validation of GaussianNB model without PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************************************************************************************\n",
      "GaussianNB Model Evaluation - with MinMaxScaler,SelectKBest & without PCA using StratifiedShuffleSplit\n",
      "*********************************************************************************************************************************\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('selector', SelectKBest(k=10, score_func=<function f_classif at 0x000000001A08E6D8>)), ('classifier', GaussianNB(priors=None))]),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid={'selector__k': [10, 15, 'all'], 'scaler': [None, MinMaxScaler(copy=True, feature_range=(0, 1))]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, scoring='f1', verbose=0)\n",
      "\tAccuracy: 0.81087\tPrecision: 0.30544\tRecall: 0.32850\tF1: 0.31655\tF2: 0.32361\n",
      "\tTotal predictions: 15000\tTrue positives:  657\tFalse positives: 1494\tFalse negatives: 1343\tTrue negatives: 11506\n",
      "\n",
      "\n",
      "*********************************************************************************************************************************\n",
      "GaussianNB parameters\n",
      "{'scoring': 'f1', 'estimator__scaler__feature_range': (0, 1), 'n_jobs': 1, 'refit': True, 'verbose': 0, 'fit_params': {}, 'estimator__selector__score_func': <function f_classif at 0x000000001A08E6D8>, 'estimator__memory': None, 'estimator__scaler': MinMaxScaler(copy=True, feature_range=(0, 1)), 'estimator__classifier': GaussianNB(priors=None), 'estimator__classifier__priors': None, 'iid': True, 'estimator__selector__k': 10, 'estimator': Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('selector', SelectKBest(k=10, score_func=<function f_classif at 0x000000001A08E6D8>)), ('classifier', GaussianNB(priors=None))]), 'estimator__steps': [('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('selector', SelectKBest(k=10, score_func=<function f_classif at 0x000000001A08E6D8>)), ('classifier', GaussianNB(priors=None))], 'error_score': 'raise', 'estimator__selector': SelectKBest(k=10, score_func=<function f_classif at 0x000000001A08E6D8>), 'estimator__scaler__copy': True, 'param_grid': {'selector__k': [10, 15, 'all'], 'scaler': [None, MinMaxScaler(copy=True, feature_range=(0, 1))]}, 'cv': None, 'pre_dispatch': '2*n_jobs'}\n",
      "*********************************************************************************************************************************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nprint\\nprint \"*********************************************************************************************************************************\"\\nprint \"Features and the Feature score of the final model\" \\ngt_kbest_scores = sorted(zip(selector.scores_, features_list_eng_all[:10]), reverse=True)\\nprint gt_kbest_scores\\nprint \"*********************************************************************************************************************************\"\\n\\n'"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"*********************************************************************************************************************************\"\n",
    "print \"GaussianNB Model Evaluation - with MinMaxScaler,SelectKBest & without PCA using StratifiedShuffleSplit\"\n",
    "print \"*********************************************************************************************************************************\"\n",
    "\n",
    "pipe = Pipeline([\n",
    "        ('scaler', preprocessing.MinMaxScaler()),\n",
    "        (\"selector\", SelectKBest()),\n",
    "        ('classifier', GaussianNB())\n",
    "    ])\n",
    "\n",
    "param_grid = {\n",
    "    'scaler': [None, preprocessing.MinMaxScaler()],\n",
    "    'selector__k': [10, 15, 'all']\n",
    "}\n",
    "\n",
    "clf_gnb_grd = GridSearchCV(pipe, param_grid, scoring='f1')\n",
    "#ptest_classifier(clf_gnb_grd, my_dataset, features_list_all)\n",
    "tester.dump_classifier_and_data(clf_gnb_grd, my_dataset, features_list_eng_all)\n",
    "tester.main();\n",
    "\n",
    "## Features and the Feature score of the final model\n",
    "print \n",
    "print \"*********************************************************************************************************************************\"\n",
    "print \"GaussianNB parameters\"\n",
    "print clf_gnb_grd.get_params()\n",
    "print \"*********************************************************************************************************************************\"\n",
    "\n",
    "'''\n",
    "print\n",
    "print \"*********************************************************************************************************************************\"\n",
    "print \"Features and the Feature score of the final model\" \n",
    "gt_kbest_scores = sorted(zip(selector.scores_, features_list_eng_all[:10]), reverse=True)\n",
    "print gt_kbest_scores\n",
    "print \"*********************************************************************************************************************************\"\n",
    "\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Tuning and Validation of DecisionTree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************************************************************************************\n",
      "DecisionTreeClassifier Model Evaluation - with MinMaxScaler,SelectKBest & PCA using StratifiedShuffleSplit\n",
      "*********************************************************************************************************************************\n",
      "Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('selector', SelectKBest(k=15, score_func=<function f_classif at 0x000000001A08E6D8>)), ('reducer', PCA(copy=True, iterated_power='auto', n_components=6, random_state=42,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('classifier', De...      min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'))])\n",
      "\tAccuracy: 0.79673\tPrecision: 0.22056\tRecall: 0.20700\tF1: 0.21357\tF2: 0.20958\n",
      "\tTotal predictions: 15000\tTrue positives:  414\tFalse positives: 1463\tFalse negatives: 1586\tTrue negatives: 11537\n",
      "\n",
      "\n",
      "*********************************************************************************************************************************\n",
      "Features and the Feature score of the final model\n",
      "*********************************************************************************************************************************\n",
      "[('ratio_of_total_payments', 22.782107829734304), ('salary', 22.610530706873778), ('ratio_to_poi', 21.06000170753658), ('total_stock_value', 18.575703268041778), ('bonus', 9.380236796811595), ('deferred_income', 8.958540049080092), ('long_term_incentive', 8.74648553212908), ('ratio_of_total_stock', 1.6988243485808538), ('total_payments', 0.761863314557665), ('exercised_stock_options', 0.22121448377482592)]\n"
     ]
    }
   ],
   "source": [
    "print \"*********************************************************************************************************************************\"\n",
    "print \"DecisionTreeClassifier Model Evaluation - with MinMaxScaler,SelectKBest & PCA using StratifiedShuffleSplit\"\n",
    "print \"*********************************************************************************************************************************\"\n",
    "\n",
    "CRITERION = ['gini', 'entropy']\n",
    "SPLITTER = ['best', 'random']\n",
    "MIN_SAMPLES_SPLIT = [2, 4, 6, 8]\n",
    "CLASS_WEIGHT = ['balanced', None]\n",
    "\n",
    "\n",
    "pipe = Pipeline([\n",
    "        ('scaler', preprocessing.MinMaxScaler()),\n",
    "        (\"selector\", SelectKBest()),\n",
    "        ('reducer', PCA(random_state=42)),\n",
    "        ('classifier', DecisionTreeClassifier())\n",
    "    ])\n",
    "\n",
    "param_grid = {\n",
    "    'scaler': [None, preprocessing.MinMaxScaler()],\n",
    "    'selector__k': [10, 15, 'all'],\n",
    "    'reducer__n_components': [1,2,6,10],\n",
    "    'classifier__criterion': CRITERION,\n",
    "    'classifier__splitter': SPLITTER,\n",
    "    'classifier__min_samples_split': MIN_SAMPLES_SPLIT,\n",
    "    'classifier__class_weight': CLASS_WEIGHT,\n",
    "}\n",
    "\n",
    "clf_dt_grd = GridSearchCV(pipe, param_grid, scoring='f1').fit(features, labels).best_estimator_\n",
    "# ptest_classifier(clf_dt_grd, my_dataset, features_list_eng_all)\n",
    "\n",
    "tester.dump_classifier_and_data(clf_dt_grd, my_dataset, features_list_eng_all)\n",
    "tester.main();\n",
    "\n",
    "'''\n",
    "print\n",
    "print \"*********************************************************************************************************************************\"\n",
    "print \"Features and the Feature score of the final model\" \n",
    "print \"*********************************************************************************************************************************\"\n",
    "dt_features_list_imp = features_list_eng_all[1:]\n",
    "feature_scores = sorted({dt_features_list_imp[i]:clf_dt_grd.get_params()['selector'].scores_[i]\n",
    "                         for i in range(0,len(dt_features_list_imp))}.items(), reverse=True, key=operator.itemgetter(1))\n",
    "print feature_scores\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <p style=\"background-color: #355667\"> <font color = 'white'> Final Model </font> </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None)\n",
      "\tAccuracy: 0.85487\tPrecision: 0.44212\tRecall: 0.33800\tF1: 0.38311\tF2: 0.35471\n",
      "\tTotal predictions: 15000\tTrue positives:  676\tFalse positives:  853\tFalse negatives: 1324\tTrue negatives: 12147\n",
      "\n",
      "\n",
      "SelectKBest scores:  [(22.78210782973431, 'total_stock_value'), (22.782107829734304, 'ratio_of_total_stock'), (22.61053070687377, 'exercised_stock_options'), (21.06000170753657, 'bonus'), (18.575703268041785, 'salary'), (16.64170707046899, 'ratio_to_poi'), (11.561887713503024, 'deferred_income'), (10.072454529369441, 'long_term_incentive'), (9.380236796811587, 'total_payments'), (9.380236796811587, 'ratio_of_total_payments')]\n",
      "\n",
      "KBest Features ['poi', 'total_stock_value', 'ratio_of_total_stock', 'exercised_stock_options', 'bonus', 'salary', 'ratio_to_poi', 'deferred_income', 'long_term_incentive', 'total_payments', 'ratio_of_total_payments']\n"
     ]
    }
   ],
   "source": [
    "# setting the CLF, my_dataset,feature_list for easy dump and testing\n",
    "\n",
    "\n",
    "clf = GaussianNB()\n",
    "my_dataset = my_dataset\n",
    "features_list = features_list_kbest\n",
    "\n",
    "tester.dump_classifier_and_data(clf, my_dataset, features_list)\n",
    "tester.main();\n",
    "\n",
    "print\n",
    "print 'SelectKBest scores: ', kbest_scores[0:10]\n",
    "print\n",
    "print 'KBest Features',features_list_kbest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Conclusion:\n",
    "\n",
    "Based on the above results, GaussianNB outperformed the DecisionTreeClassifier. The comparison of results from <b> GaussianNB model </b> at different stages is summarized below for perusal:\n",
    "\n",
    "<p style=\"background-color: green\"> <font color = 'white'> <b>Performance with new engineered features & SelectKBest Feature Selection (Final Model) is: </b></font> </p>\n",
    "\n",
    "<b>\n",
    "Precision = 44.21%\n",
    "Recall = 33.80%\n",
    "F1 = 38.31%\n",
    "</b>\n",
    "\n",
    "<p style=\"background-color: maroon\"> <font color = 'white'> <b>Baseline Performance with inherent features (no engineered features:) </b></font> </p>\n",
    "\n",
    "<b>\n",
    "Precision = 25.45%\n",
    "Recall = 37.65%\n",
    "F1 = 30.37%\n",
    "</b>\n",
    "\n",
    "\n",
    "<p style=\"background-color: maroon\"> <font color = 'white'> <b>Performance of the model after Tuning: </b></font> </p>\n",
    "\n",
    "<b> Without PCA reduction\n",
    "Precision = 30.54%\n",
    "Recall = 32.85%\n",
    "F1 = 31.65%\n",
    "</b>\n",
    "\n",
    "<b> With PCA reduction\n",
    "Precision = 36.72%\n",
    "Recall = 25.10%\n",
    "F1 = 29.82%\n",
    "</b>\n",
    "<p>\n",
    "The Features that were used in the final model are listed below:\n",
    "\n",
    "\n",
    "Features and the Feature score of the final model <br>\n",
    "[(22.78210782973431, 'total_stock_value'), <br>\n",
    "(22.782107829734304, 'ratio_of_total_stock'), <br>\n",
    "(22.61053070687377, 'exercised_stock_options'),<br>\n",
    "(21.06000170753657, 'bonus'), <br>\n",
    "(18.575703268041785, 'salary'),<br>\n",
    "(16.64170707046899, 'ratio_to_poi'),<br>\n",
    "(11.561887713503024, 'deferred_income'),<br>\n",
    "(10.072454529369441, 'long_term_incentive'),<br>\n",
    "(9.380236796811587, 'total_payments'),<br>\n",
    "(9.380236796811587, 'ratio_of_total_payments')]<br>\n",
    "\n",
    "\n",
    "As excpect the Scaler and PCA did not improve the metrics in the case of GaussianNB and hence my final model did not use them. Interestingly in this case, when Feature Scaling and PCA was applied to the features the F1 score decreased thereby indicating that it led to information loss which the GaussianNB benefitted from.<br>\n",
    "\n",
    "What does the Precision and Recall from the final model mean? A recall of 34% implies that when the person is indeed a POI, the classifier will detect the same 34 out of 100 instances. This is not ideal in the real world scenario. It is important important to note though that it is likely that we could enhance the metric further if further features are made available to the model. This is something that I could further explore to augment my Machine learning skills :)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"C:\\Users\\ss842p\\Documents\\ATT Sab Documents\\Nano Degree\\Data Analyst\\Machine Learning\\ud120-projects-master\\ud120-projects-master\\final_project\\summary.jpeg\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
