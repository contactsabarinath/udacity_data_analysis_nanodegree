{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import codecs\n",
    "import pprint\n",
    "import re\n",
    "import xml.etree.cElementTree as ET\n",
    "import cerberus\n",
    "import schema\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Files\n",
    "#OSM_PATH = \"./dbprep/redmond_bell_kirk.xml\"\n",
    "OSM_FILE = \"./dbprep/redmond_bell_kirk.xml\"\n",
    "SAMPLE_FILE = \"./dbprep/rbk_samp.xml\"\n",
    "# switch file to SAMPLE_FILE or OSM_FILE depending on DRAFT / Production Cut\n",
    "# FILE = SAMPLE_FILE \n",
    "FILE = OSM_FILE\n",
    "SCHEMA = schema.schema\n",
    "# Output Files\n",
    "NODES_PATH = \"./dbprep/nodes.csv\"\n",
    "NODE_TAGS_PATH = \"./dbprep/nodes_tags.csv\"\n",
    "WAYS_PATH = \"./dbprep/ways.csv\"\n",
    "WAY_NODES_PATH = \"./dbprep/ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"./dbprep/ways_tags.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex functions\n",
    "\n",
    "lower_re = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon_re = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars_re = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "phone_re = re.compile(r''' ([2-9][0-9][0-9])\\D*(\\d{3})\\D* (\\d{4})\\D*(\\d*)$''', re.VERBOSE)\n",
    "zcode_re = re.compile(r'''(\\d{5})''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "tag_freq = defaultdict(int)\n",
    "tag_key = defaultdict(int)\n",
    "elem_tag = {}\n",
    "elem_tags = []\n",
    "street_types = defaultdict(set)\n",
    "\n",
    "expected = [\"Redmond\",\"Kirkland\",\"Woodinville\",\"Willows\",\"Sammamish\",\"Juanita\",\n",
    "            \"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\",\"Park\", \"Commons\",\"Way\",\"Circle\",\n",
    "            \"North\",\"East\",\"West\",\"Northeast\",\"Center\",\"South\",\"Central\",\"Northwest\",\n",
    "           \"Parkplace\",\"Totem\",\"Lake\",\"Bear\",\"Creek\",\"Leary\",\"Forbes\",\"Railroad\",\"Hill\",\"Union\",\"River\",\n",
    "           \"State\",\"Cedar\",\"Ohde\",\"Slater\",\"Lakeview\",\"Avondale\",\"Observation\",\"Bridlewood\",\"Old\",\"Cleveland\",\"Alexander\"]\n",
    "\n",
    "# UPDATE THIS VARIABLE\n",
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"st\": \"Street\",\n",
    "            \"ST\": \"Street\",\n",
    "            \"Ave\": \"Avenue\",\n",
    "            \"Ave.\": \"Avenue\",\n",
    "            \"AVE\": \"Avenue\",\n",
    "            \"ave\": \"Avenue\",\n",
    "            \"Rd\": \"Road\",\n",
    "            \"Rd.\": \"Road\",\n",
    "           \"NE\" : \"Northeast\",\n",
    "           \"ne\" : \"Northeast\",\n",
    "           \"Ln\" : \"Lane\",\n",
    "           \"LN\" : \"Lane\",\n",
    "           \"WY\" : \"Way\",\n",
    "           \"Pl\" : \"Place\",\n",
    "           \"PL\" : \"Place\",\n",
    "           \"Ct\" :\"Court\",\n",
    "           \"Dr\" :\"Drive\",\n",
    "           \"Remond\" : \"Redmond\",\n",
    "           \"Northest\":\"Northeast\"           \n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function accepts \n",
    "    a) street details from the data file, \n",
    "    b) mapping dictionary of uncoventional street type to standard street type for this project\n",
    "    c) expected street names\n",
    "& returns either cleaned out, standarized street names\n",
    "\n",
    "'''\n",
    "def standard_street_name(name, mapst=mapping,expst=expected):\n",
    "    \n",
    "    st = name.split()\n",
    "    parsed_street = ''\n",
    "\n",
    "    for s in st:\n",
    "        if s.isalpha(): # is the sliced street part alphabetic? as the number part need not be massaged\n",
    "            if s not in expst:\n",
    "                if mapst.get(s,0) <> 0:\n",
    "                    parsed_street = parsed_street + ' ' + mapst[s]\n",
    "                else:\n",
    "                    print name, \" Please handle -> \",s\n",
    "            else:\n",
    "                parsed_street = parsed_street + ' ' + s\n",
    "        else:\n",
    "            parsed_street = parsed_street + ' ' + s\n",
    "    #print name,' -> ',parsed_street.strip()\n",
    "    return parsed_street.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function accepts phone number from the data file and the phone regex function and \n",
    "returns either a) cleaned out, standarized phone or \n",
    "               b) Error in case of anamoly\n",
    "'''\n",
    "def standard_phone_num(phnum, pphone_re =phone_re):\n",
    "    ptemp = ''\n",
    "    pno = ''\n",
    "    ptemp_grp = pphone_re.search(phnum)\n",
    "    if ptemp_grp:\n",
    "        \n",
    "        ptemp = ptemp_grp.groups()\n",
    "        pno =  ptemp[0]+'-'+ptemp[1]+'-'+ptemp[2]\n",
    "        if ptemp[3] <>'': # if there is extenion associated with the phone #\n",
    "            pno = pno + '-'+ptemp[3]\n",
    "\n",
    "    else:\n",
    "        #print \"No match -> \", phnum\n",
    "        pno = 'Error'\n",
    "    return pno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function accepts postal code from the data file and the zip regex function and \n",
    "returns either a) cleaned out, standarized zip code or \n",
    "               b) Error in case of anamoly\n",
    "'''\n",
    "def standard_zip(pcode, pzcode_re =zcode_re):\n",
    "    ztemp = pzcode_re.search(pcode)\n",
    "    if ztemp:\n",
    "        zipcode = ztemp.groups()\n",
    "        #print \"zip code > 5 : \", elem.attrib['v'], ' -> ',ztemp[0]\n",
    "        return zipcode[0]\n",
    "    else:\n",
    "        return 'Error'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def any_foreign_char(s):\n",
    "    '''function accepts a string and returns True when there are foreign char in the string'''\n",
    "    # reference https://stackoverflow.com/questions/27084617/detect-strings-with-non-english-characters-in-python\n",
    "    try:\n",
    "        s.encode(encoding='utf-8').decode('ascii')\n",
    "    except UnicodeDecodeError:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skip_tag_parse(tag_key,tag_value,\n",
    "                   pproblem_chars_re=problemchars_re,pphone_re=phone_re):\n",
    "    '''function returns list of Boolean flag indicating if the tag need to be skipped and \n",
    "      also the specific sections which caused the validation to fail\n",
    "    '''\n",
    "    is_tag_key_problem = False\n",
    "    is_foreign_code_problem = False\n",
    "    is_phone_problem = False\n",
    "    is_zip_problem = False\n",
    "    skip_tag = False\n",
    "    \n",
    "    if pproblem_chars_re.search(tag_key):\n",
    "        skip_tag = True\n",
    "        is_tag_key_problem = True\n",
    "    if \"name:\" in tag_key and any_foreign_char(tag_value): #foreign char in name (not name:), not or source tag is genuine\n",
    "        skip_tag = True\n",
    "        is_foreign_code_problem = True\n",
    "    if tag_key == 'phone': # the tag key source:phone is genuine\n",
    "        pnum = standard_phone_num(tag_value)\n",
    "        if pnum == 'Error':\n",
    "            skip_tag = True\n",
    "            is_phone_problem = True\n",
    "    if \"postcode\" in tag_key:\n",
    "        zipcode = standard_zip(tag_value)\n",
    "        if zipcode == 'Error':\n",
    "            skip_tag = True\n",
    "            is_zip_problem = True\n",
    "            \n",
    "        \n",
    "    \n",
    "    #return the list of flags to inspect which test flagged the tag\n",
    "    return[skip_tag,is_tag_key_problem,is_foreign_code_problem,is_phone_problem,is_zip_problem]\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  node_tag_fields=NODE_TAGS_FIELDS,wy_tag_fields=WAY_TAGS_FIELDS,wy_nodes_fields=WAY_NODES_FIELDS,    \n",
    "                  default_tag_type='regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "    ''' This function checks the following:\n",
    "          a)checks if tag keys have problem chars in them and if found - discards the tag\n",
    "          b)checks if the tag value have any foreign char in them and if found - discards the tag\n",
    "          c)checks for street type and massages them to a standard format\n",
    "          d)checks for the postalcode and massages them to the standard 5 digit zip code\n",
    "          e)checks for phone number and massages them to a standard format\n",
    "    '''\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    node_tags = []  # Handle secondary tags the same way for both node and way elements\n",
    "    node_tag = {}\n",
    "    way_tags = []    \n",
    "    way_tag = {}\n",
    "    way_nodes = []\n",
    "    way_node = {}\n",
    "    node_id = ''\n",
    "    way_id = ''\n",
    "    typ = ''\n",
    "    way_typ = ''\n",
    "    skip_tag = False\n",
    "\n",
    "    # Node element processing begins\n",
    "    if element.tag == 'node':\n",
    "\n",
    "        # iterate on node_attr_fields so that only interested fields are parsed\n",
    "        for field in node_attr_fields:\n",
    "            node_attribs[field] = element.attrib[field] # building the node attributes dictionary\n",
    "            if field == 'id':\n",
    "                node_id = element.attrib[field] # store the node id for referencing the child elements node id           \n",
    "        \n",
    "        # begin the processing of child element of the node\n",
    "        for child in element:\n",
    "            if child.tag == 'tag':\n",
    "                typ = '' # this variable to hold value regular / keytype based on the : char of tag key \n",
    "\n",
    "                '''do not parse \n",
    "                  1) if the tag key has problem chars in them or \n",
    "                  2) incase of name: tag, if the tag value has any foreign chars in the  or\n",
    "                  3) incase of phone tag, if the phone number is anomalous\n",
    "                  4) incase of zip code tag, if the zip code is anomalous\n",
    "                '''\n",
    "                skip_tag = skip_tag_parse(child.attrib['k'],child.attrib['v'])\n",
    "                #skip_tag[0] is the boolean flag. A True means the tag need not be parsed\n",
    "                if skip_tag[0] == False:\n",
    "                    for field in node_tag_fields: # iterate through node tag fields\n",
    "                        if field == 'id':\n",
    "                            node_tag[field] = node_id #store the parent node id for referencing parent node\n",
    "                        elif field == 'key':\n",
    "                            if \":\" in child.attrib['k']:\n",
    "                                node_tag[field] = child.attrib['k'].split(\":\", 1)[1]\n",
    "                                typ = child.attrib['k'].split(\":\", 1)[0]\n",
    "                            else:\n",
    "                                node_tag[field] = child.attrib['k']\n",
    "                        elif field == 'value':\n",
    "                                if  \"street\" in child.attrib['k']:\n",
    "                                    node_tag[field] = standard_street_name(child.attrib['v'])\n",
    "\n",
    "                                elif  child.attrib['k'] == 'phone':\n",
    "                                    #std_phone = standard_phone_num(child.attrib['v'])\n",
    "                                    node_tag[field] = standard_phone_num(child.attrib['v'])\n",
    "                                    \n",
    "                                elif  \"postcode\" in child.attrib['k']:\n",
    "                                    #std_zip = standard_zip(child.attrib['v'])\n",
    "                                    node_tag[field] = standard_zip(child.attrib['v'])\n",
    "                                    \n",
    "                                else:\n",
    "                                    node_tag[field] = child.attrib['v']\n",
    "                        elif field == 'type':\n",
    "                            if typ =='':\n",
    "                                node_tag[field] = \"regular\"\n",
    "                            else:\n",
    "                                 node_tag[field] = typ\n",
    "                    node_tags.append(node_tag.copy()) \n",
    "        return {'node': node_attribs, 'node_tags': node_tags} \n",
    "        \n",
    "        \n",
    "    elif element.tag == 'way':\n",
    "        for field in way_attr_fields:\n",
    "            way_attribs[field] = element.attrib[field]\n",
    "            \n",
    "            if field == 'id':\n",
    "                way_id = element.attrib[field]\n",
    "\n",
    "        waynd_idx = 0 # index to track way nd tag\n",
    "        \n",
    "        for child in element:\n",
    "            way_typ = ''\n",
    "            \n",
    "            if child.tag == 'tag':\n",
    "                \n",
    "                skip_tag = skip_tag_parse(child.attrib['k'],child.attrib['v'])\n",
    "                if skip_tag[0] == False:\n",
    "                    \n",
    "                    for field in wy_tag_fields:\n",
    "                        if field == 'id':\n",
    "                            way_tag[field] = way_id\n",
    "                        elif field == 'key':\n",
    "                            if \":\" in child.attrib['k']:\n",
    "                                way_tag[field] = child.attrib['k'].split(\":\", 1)[1]\n",
    "                                way_typ = child.attrib['k'].split(\":\", 1)[0]\n",
    "                            else:\n",
    "                                way_tag[field] = child.attrib['k']\n",
    "                        elif field == 'value':\n",
    "                                if  \"street\" in child.attrib['k']:\n",
    "                                    way_tag[field] = standard_street_name(child.attrib['v'])\n",
    "\n",
    "                                elif  child.attrib['k'] == 'phone':\n",
    "                                    #std_phone = standard_phone_num(child.attrib['v'])\n",
    "                                    way_tag[field] = standard_phone_num(child.attrib['v'])\n",
    "                                    \n",
    "                                elif  \"postcode\" in child.attrib['k']:\n",
    "                                    #std_zip = standard_zip(child.attrib['v'])\n",
    "                                    way_tag[field] = standard_zip(child.attrib['v'])\n",
    "                                    \n",
    "                                else:\n",
    "                                    way_tag[field] = child.attrib['v']                            \n",
    "                        elif field == 'type':\n",
    "                            if way_typ =='':\n",
    "                                way_tag[field] = \"regular\"\n",
    "                            else:\n",
    "                                way_tag[field] = way_typ\n",
    "                    way_tags.append(way_tag.copy())\n",
    "\n",
    "            elif child.tag == 'nd':\n",
    "                for wnfield in wy_nodes_fields:\n",
    "                    if wnfield == 'id':\n",
    "                        way_node[wnfield] = way_id\n",
    "                    elif wnfield == 'node_id':\n",
    "                        way_node[wnfield] = child.attrib['ref']\n",
    "                    elif wnfield == 'position':\n",
    "                        way_node[wnfield] = waynd_idx\n",
    "                waynd_idx = waynd_idx + 1  # increment the index by 1 for the next nd tag withing the same parent way tag\n",
    "                way_nodes.append(way_node.copy())    \n",
    "                \n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': way_tags}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_element(pfile, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(pfile, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "\n",
    "\n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_string = pprint.pformat(errors)\n",
    "        \n",
    "        raise Exception(message_string.format(field, error_string))\n",
    "\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ================================================== #\n",
    "#               Main Function                        #\n",
    "# ================================================== #\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "        \n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            \n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "            \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Note: Validation is ~ 10X slower. For the project consider using a small\n",
    "    # sample of the map when validating.\n",
    "    #process_map(OSM_PATH, validate=True)\n",
    "    process_map(FILE, validate=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def element_counts(file_in):\n",
    "    ''' function counts the number of Node, Node tags, Way, Way tags and Ways node tags. \n",
    "    Additionally it provides the count of  Node tags & Way tags that are discarded by my code.\n",
    "    The idea is to validate that the count that is imported on to db by comparing against the discarded tags'''\n",
    "    node_freq = defaultdict(int)\n",
    "    node_set = set()\n",
    "    node_tag_freq = defaultdict(int)\n",
    "    skipped_node_tag_count = 0\n",
    "    \n",
    "    way_freq = defaultdict(int)\n",
    "    way_set = set()\n",
    "    way_tag_freq = defaultdict(int)\n",
    "    skipped_way_tag_count = 0\n",
    "    \n",
    "    for element in get_element(file_in, tags=('node', 'way')):\n",
    "        if element.tag == 'node':\n",
    "            node_freq[element.tag] +=1\n",
    "            node_set.add(element.attrib['id'])\n",
    "            for child in element:\n",
    "                if child.tag =='tag':\n",
    "                    node_tag_freq[child.tag] +=1\n",
    "                    skip_data = skip_tag_parse(child.attrib['k'],child.attrib['v'])\n",
    "                    if skip_data[0] == True:\n",
    "                        skipped_node_tag_count += 1 \n",
    "        elif element.tag == 'way':\n",
    "            way_freq[element.tag] +=1\n",
    "            way_set.add(element.attrib['id'])\n",
    "            for child in element:\n",
    "                if child.tag =='tag':\n",
    "                    way_tag_freq[child.tag] +=1 \n",
    "                    skip_data = skip_tag_parse(child.attrib['k'],child.attrib['v'])\n",
    "                    if skip_data[0] == True:\n",
    "                        skipped_way_tag_count += 1                     \n",
    "                elif child.tag == 'nd':\n",
    "                    way_tag_freq[child.tag] +=1 \n",
    "                        \n",
    "                    \n",
    "    print '******************************************************************************'\n",
    "    print '********* Count of Node Elements based on the OSM File ************'\n",
    "    print '******************************************************************************'\n",
    "    print \"Node Frequeceny is :\", node_freq\n",
    "    print\n",
    "    print \"Unique node count is :\", len(node_set)\n",
    "    print \n",
    "    print \"Count of Tag elemnt under Node is :\",node_tag_freq\n",
    "    print \n",
    "    print \"Count of Tag elements under Node that are filerted out is:\",skipped_node_tag_count\n",
    "    \n",
    "    print \n",
    "    print '******************************************************************************'\n",
    "    print '********* Count of Node Elements based on the OSM File ************'\n",
    "    print '******************************************************************************'\n",
    "    print \"Way Frequeceny is :\", way_freq  \n",
    "    print\n",
    "    print \"Unique Way count is :\",len(way_set)\n",
    "    print \n",
    "    print \"Count of Tag/nd elemnt under Way is :\",way_tag_freq\n",
    "    print \n",
    "    print \"Count of Tag elements under Way that are filerted out is:\",skipped_way_tag_count   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************\n",
      "********* Count of Node Elements based on the OSM File ************\n",
      "******************************************************************************\n",
      "Node Frequeceny is : defaultdict(<type 'int'>, {'node': 328395})\n",
      "\n",
      "Unique node count is : 328395\n",
      "\n",
      "Count of Tag elemnt under Node is : defaultdict(<type 'int'>, {'tag': 66620})\n",
      "\n",
      "Count of Tag elements under Node that are filerted out is: 18\n",
      "\n",
      "******************************************************************************\n",
      "********* Count of Node Elements based on the OSM File ************\n",
      "******************************************************************************\n",
      "Way Frequeceny is : defaultdict(<type 'int'>, {'way': 35416})\n",
      "\n",
      "Unique Way count is : 35416\n",
      "\n",
      "Count of Tag/nd elemnt under Way is : defaultdict(<type 'int'>, {'tag': 130992, 'nd': 360231})\n",
      "\n",
      "Count of Tag elements under Way that are filerted out is: 1\n"
     ]
    }
   ],
   "source": [
    "element_counts(OSM_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tester Function: test street_name, zip and phone_number anomaly\n",
    "'''\n",
    "This function is used to print out any anomaly that is seen in street name and in the phone\n",
    "Note: Street name anomaly is ironed out by building suitable data structure i.e. mapping dictionary and expected list\n",
    "'''\n",
    "def test_street_phone_zip_anomaly(ifile):\n",
    "    for event, elem in ET.iterparse(ifile):\n",
    "        if elem.tag == 'tag':\n",
    "            if \"street\" in elem.attrib['k']:\n",
    "                n = standard_street_name(elem.attrib['v'])\n",
    "            if \"phone\" in elem.attrib['k']:\n",
    "                phone = standard_phone_num(elem.attrib['v'])\n",
    "                if phone == 'Error':\n",
    "                    print elem.attrib['k'],' : ',elem.attrib['v'], ' -> ',phone \n",
    "            if  \"postcode\" in elem.attrib['k']:\n",
    "                zipcode = standard_zip(elem.attrib['v'])\n",
    "                if zipcode <> elem.attrib['v']:\n",
    "                    print elem.attrib['k'], ' : ', elem.attrib['v'] ,' -> ',zipcode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_street_phone_zip_anomaly(OSM_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tester Function: test function to trap anamolous tag that needs to be skipped when loading the CSV\n",
    "'''\n",
    "This function is used to emit those tags that are discarded from being parsed into CSV\n",
    "'''\n",
    "def test_skip_parse(ifile):\n",
    "    #print ifile\n",
    "    for event, elem in ET.iterparse(ifile):\n",
    "        if elem.tag == 'node' or elem.tag == 'way':\n",
    "            #print elem\n",
    "            for child in elem:\n",
    "                if child.tag == 'tag':\n",
    "                    try:\n",
    "                        skip_data = skip_tag_parse(child.attrib['k'],child.attrib['v'])\n",
    "                    except KeyError, e:\n",
    "                        print child.tag, child.attrib\n",
    "                    if skip_data[0] == True:\n",
    "                        print skip_data,child.attrib['k'],' -> ',child.attrib['v']\n",
    "                        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, False, True, False, False] name:ar  ->  ريدموند\n",
      "[True, False, True, False, False] name:bg  ->  Редмънд\n",
      "[True, False, True, False, False] name:fa  ->  ردموند\n",
      "[True, False, True, False, False] name:he  ->  רדמונד\n",
      "[True, False, True, False, False] name:ja  ->  レドモンド\n",
      "[True, False, True, False, False] name:ko  ->  레드먼드\n",
      "[True, False, True, False, False] name:ru  ->  Редмонд\n",
      "[True, False, True, False, False] name:ta  ->  ரெட்மாண்ட்\n",
      "[True, False, True, False, False] name:uk  ->  Редмонд\n",
      "[True, False, True, False, False] name:zh  ->  雷德蒙德\n",
      "[True, False, True, False, False] name:ar  ->  كيركلاند\n",
      "[True, False, True, False, False] name:bg  ->  Къркланд\n",
      "[True, False, True, False, False] name:fa  ->  کرکلند\n",
      "[True, False, True, False, False] name:ja  ->  カークランド\n",
      "[True, False, True, False, False] name:ko  ->  커클랜드\n",
      "[True, False, True, False, False] name:zh  ->  柯克蘭\n",
      "[True, False, False, False, True] addr:postcode  ->  W Lake Sammamish Pkwy NE\n",
      "[True, False, False, True, False] phone  ->  +1-425-569-090\n",
      "[True, False, False, True, False] phone  ->  425-558-110\n"
     ]
    }
   ],
   "source": [
    "test_skip_parse(OSM_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
